{
    "config": {
        "error": {
            "cannot_connect": "Nepodarilo sa pripoji\u0165",
            "download_failed": "Stiahnutie modelu zlyhalo",
            "unknown": "Neo\u010dak\u00e1van\u00e1 chyba"
        },
        "progress": {
            "download": "Po\u010dkajte, pros\u00edm, k\u00fdm sa model stiahne, \u010do m\u00f4\u017ee trva\u0165 ve\u013emi dlho. Podrobnej\u0161ie inform\u00e1cie n\u00e1jdete v z\u00e1znamoch servera Ollama."
        },
        "step": {
            "download": {
                "title": "Stiahnutie modelu"
            },
            "user": {
                "data": {
                    "model": "Model",
                    "url": "URL"
                }
            }
        }
    },
    "options": {
        "step": {
            "init": {
                "data": {
                    "keep_alive": "Udr\u017ea\u0165 na\u017eive",
                    "llm_hass_api": "Ovl\u00e1danie Home Assistant",
                    "max_history": "Maxim\u00e1lny po\u010det spr\u00e1v hist\u00f3rie",
                    "prompt": "In\u0161trukcie"
                },
                "data_description": {
                    "keep_alive": "Trvanie v sekund\u00e1ch, po\u010das ktor\u00e9ho m\u00e1 Ollama uchov\u00e1va\u0165 model v pam\u00e4ti. -1 = neur\u010dit\u00e9, 0 = nikdy.",
                    "prompt": "Pokyn, ako by mal LLM reagova\u0165. M\u00f4\u017ee \u00eds\u0165 o \u0161abl\u00f3nu."
                }
            }
        }
    }
}