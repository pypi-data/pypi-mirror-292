#!/usr/bin/env python3
import argparse
import subprocess
import os
import os.path
from shlex import quote
from sys import stdin, stdout, stderr
from snakemake.utils import read_job_properties

parser=argparse.ArgumentParser(add_help=False)

parser.add_argument("--depend", help="Space separated list of ids for jobs this job should depend on.", default="", type=str)
parser.add_argument("--extra", help="Any additional qsub args", default="", type=str)
parser.add_argument("jobscript")

args = parser.parse_args()

cmd = ["sbatch --parseable -D . -j y"]  # always start in wd, always join out/err logs

job_properties = read_job_properties(args.jobscript)
resources = job_properties.get("resources", {})
cluster = job_properties.get("cluster", {})

# dependencies
if args.depend:
    depstr = ":".join(args.depend.split(" "))
    cmd.append("--dependency")
    cmd.append(quote(f"depend=afterok:{depstr}"))

# threads
threads = job_properties.get("threads", 2)
cmd.extend([
        "--ntasks=2", 
        f"--cpus-per-task={threads}"
])

# memory
mem = int(resources.get("mem_mb", 2000))
cmd.append(f"--mem={mem}")

# walltime
time_min = int(resources.get("time_min", 60)) * 60
cmd.append(f"--time={time_min}")

# jobfs
disk_mb = resources.get("disk_mb", 10)
cmd.append(f"--tmp={disk_mb}M'")

# queue
# defaults: normal, unless internet=true
# queue = "normal"
# if resources.get("internet", False):
#     queue="copyq"
# # override with queue from resources
# queue = resources.get("queue", queue)
# cmd.append(f"-q '{queue}'")

# logs
out = None
if "output" in cluster:
    out = cluster["output"]
if "output" in resources:
    out = resources["output"]
if out:
    os.makedirs(out, exist_ok=True, mode=0o775)
    cmd.append(f"--output={out}/snakemake_slurm_%J.log")

cmd.append(args.jobscript)
cmd = " ".join(cmd)

if cluster.get("DEBUG", False):
    print(cmd, file=stderr)
res = subprocess.check_output(cmd, shell=True).decode()
print(res.strip())
