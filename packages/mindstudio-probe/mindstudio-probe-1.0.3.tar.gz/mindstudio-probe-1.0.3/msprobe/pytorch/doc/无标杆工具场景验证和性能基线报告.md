# 无标杆工具场景验证和性能基线报告

## 环境信息

NPU：Atlas A2 训练系列产品

CPU：

![输入图片说明](img/cpu_info.png)

Torch：2.1.0

CANN：8.0.T5

除上述环境信息影响性能外，API的数量、种类以及Shape都会对性能产生影响，因此本次选取不同场景网络和不同算子进行测试。

## 模型信息和性能基线

大模型在使用msprobe工具dump数据时，建议先简化模型层数，减少dump数据量。

以下场景的性能基线测试数据均为多次测试后取平均值，因此实际运行时性能数据可能会根据环境状态稍有浮动。



### LLaMA2-7B

NUM_LAYER：1，1卡，主要数据类型：FLOAT16，模型来源: ascend/ModelLink
其中，softmax算子为FLOAT32，输入输出均为2G大小，为模型最大显存开销的API。

在该模型下、对无标杆工具处理模式、插装范围、扰动方式组合下性能和显存基线进行覆盖。

性能基线报告
其中耗时为训练10步，去除第一步耗时所得的平均每步耗时。

| 处理模式                     | 前/反向                 | 算子范围                 | 扰动方式 | 耗时（s） | 显存峰值（GB） | 耗时膨胀倍数 | 显存峰值膨胀倍数 | 备注                           |
|--------------------------------|-----------------------------------|-----------------|----------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|
| /        | /       | /           | /                 | 0.24      | 13.69          | 1            | 1                | 混精模式基线                   |
| check    | 前      | ["softmax"] | improve_precision | 0.26      | 13.69          | 1.08         | 1             | softmax本身为高精度，跳过      |
| check    | 前      | ["softmax"] | add_noise         | 0.54      | 19.17          | 2.25         | 1.40             |                                |
| check    | 前      | ["softmax"] | bit_noise         | 0.56      | 19.17          | 2.33         | 1.40             |                                |
| check    | 前      | ["softmax"] | change_value      | 0.48      | 14.9           | 2            | 1.09             |                                |
| check    | 前      | ["softmax"] | no_change         | 0.47      | 14.9           | 1.96         | 1.09             |                                |
| check | 前 | ["softmax"] | to_cpu | 26.45 | 22.67 | 110.21 | 1.66 | 不建议整网 |
| check    | 前      | ["matmul"]  | improve_precision | 0.57      | 13.69          | 2.38       | 1                |                                |
| check    | 前      | ["matmul"]  | change_value      | 0.48      | 13.69          | 2            | 1                |                                |
| check | 前 | ["matmul"] | to_cpu | 78.43 | 19.20 | 326.79 | 1.40 | 不建议整网 |
| check | 前 | [] | improve_precision | 3.45 | 18.79 | 14.37 | 1.37 | |
| check | 前 | [] | add_noise | 4.67 | 19.17 | 19.46 | 1.40 | |
| check | 前 | [] | bit_noise | 16.99 | 19.17 | 70.79 | 1.40 | |
| check | 前 | [] | no_change | 3.22 | 14.90 | 13.42 | 1.09 | |
| check    | 反      | ["softmax"] | improve_precision | 6.23      | 25.69          | 25.96        | 1.88             | 不建议整网                     |
| check    | 反      | ["softmax"] | change_value      | 22.76     | 25.69          | 94.83        | 1.88             | 不建议整网                     |
| check | 反 | ["softmax"] | to_cpu | 141.71 | 26.19 | 590.46 | 1.91 | 不建议整网 |
| fix      | 前      | ["softmax"] | to_cpu            | 9.70      | 16.67          | 40.42        | 1.22             | 不支持整网、不支持反向         |
| fix      | 前      | ["softmax"] | improve_precision | 0.26      | 14.67          | 1.08         | 1.07             | 不支持整网、不支持反向         |
| 预热     | 前      | []          | improve_precision | 155.07 | 24.79 | 646.13 | 1.81 | 低精度模型基线、只测预热的迭代 |
| 预热     | 反      | []          | improve_precision | 72.29 | 22.01 | 301.21 | 1.61 | 低精度模型基线、只测预热的迭代，grad_output为高精度的算子跳过 |

### Aquila2-7B

NUM_LAYER：1，1卡，主要数据类型：FLOAT16，模型来源: ascend/ModelLink

| 处理模式                     | 前/反向                 | 算子范围                 | 扰动方式 | 耗时（s） | 显存峰值（GB） | 耗时膨胀倍数 | 显存峰值膨胀倍数 | 备注                           |
|--------------------------------|-----------------------------------|-----------------|----------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|
| /        | /       | /           | /                 | 0.17 | 13.66 | 1            | 1                | 混精模式基线                   |
| check    | 前      | []          | improve_precision | 1.57 | 14.24 | 9.24 | 1.04 |                                |
| check    | 反      | []          | add_noise         | 21.05 | 14.19 | 123.82 | 1.04 |                                |
| fix      | 前      | []          | improve_precision | 0.95 | 15.55 | 5.59 | 1.14 |                                |

### Baichuan2-7B

NUM_LAYER：1，1卡，主要数据类型：FLOAT16，模型来源: ascend/ModelLink

| 处理模式                     | 前/反向                 | 算子范围                 | 扰动方式 | 耗时（s） | 显存峰值（GB） | 耗时膨胀倍数 | 显存峰值膨胀倍数 | 备注                           |
|--------------------------------|-----------------------------------|-----------------|----------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|
| /        | /       | /           | /                 | 0.26 | 12.12 | 1            | 1                | 混精模式基线                   |
| check    | 前      | []          | improve_precision | 1.02 | 12.27 | 3.92 | 1.01 |                                |
| check    | 反      | []          | add_noise         | 11.15 | 12.67 | 42.88 | 1.05 |                                |
| fix      | 前      | []          | improve_precision | 0.95 | 12.82 | 3.65 | 1.06 |                                |

### Bloom-7B

NUM_LAYER：1，1卡，主要数据类型：FLOAT16，模型来源: ascend/ModelLink

| 处理模式                     | 前/反向                 | 算子范围                 | 扰动方式 | 耗时（s） | 显存峰值（GB） | 耗时膨胀倍数 | 显存峰值膨胀倍数 | 备注                           |
|--------------------------------|-----------------------------------|-----------------|----------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|
| /        | /       | /           | /                 | 0.14 | 9.51 | 1            | 1                | 混精模式基线                   |
| check    | 前      | []          | improve_precision | 1.64 | 11.58 | 11.71 | 1.22 |                                |
| check    | 反      | []          | add_noise         | 17.15 | 9.51 | 122.5 | 1 |                                |
| fix      | 前      | []          | improve_precision | 0.87 | 10.62 | 6.21 | 1.12 |                                |

### Interlm-7B

NUM_LAYER：1，1卡，主要数据类型：FLOAT16，模型来源: ascend/ModelLink

| 处理模式                     | 前/反向                 | 算子范围                 | 扰动方式 | 耗时（s） | 显存峰值（GB） | 耗时膨胀倍数 | 显存峰值膨胀倍数 | 备注                           |
|--------------------------------|-----------------------------------|-----------------|----------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|
| /        | /       | /           | /                 | 0.13 | 10.76 | 1            | 1                | 混精模式基线                   |
| check    | 前      | []          | improve_precision | 1.19 | 11.68 | 9.15 | 1.09 |                                |
| check    | 反      | []          | add_noise         | 11.69 | 10.89 | 89.92 | 1.01 |                                |
| fix      | 前      | []          | improve_precision | 0.75 | 11.68 | 5.77 | 1.09 |                                |

### Qwen-7B

NUM_LAYER：1，1卡，主要数据类型：FLOAT16，模型来源: ascend/ModelLink

| 处理模式                     | 前/反向                 | 算子范围                 | 扰动方式 | 耗时（s） | 显存峰值（GB） | 耗时膨胀倍数 | 显存峰值膨胀倍数 | 备注                           |
|--------------------------------|-----------------------------------|-----------------|----------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|
| /        | /       | /           | /                 | 0.28 | 18.41 | 1            | 1                | 混精模式基线                   |
| check    | 前      | []          | improve_precision | 2.34 | 23.18 | 8.36 | 1.26 |                                |
| check    | 反      | []          | add_noise         | 22.07 | 19.47 | 78.82 | 1.06 |                                |
| fix      | 前      | []          | improve_precision | 1.31 | 21.11 | 4.68 | 1.15 |                                |

### Gemma-7B

NUM_LAYER：1，1卡，主要数据类型：FLOAT16，模型来源: ascend/ModelLink

| 处理模式                     | 前/反向                 | 算子范围                 | 扰动方式 | 耗时（s） | 显存峰值（GB） | 耗时膨胀倍数 | 显存峰值膨胀倍数 | 备注                           |
|--------------------------------|-----------------------------------|-----------------|----------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|
| /        | /       | /           | /                 | 0.15 | 11.06 | 1            | 1                | 混精模式基线                   |
| check    | 前      | []          | improve_precision | 1.49 | 13.17 | 9.93 | 1.19 |                                |
| check    | 反      | []          | add_noise         | 16.69 | 11.06 | 111.27 | 1 |                                |
| fix      | 前      | []          | improve_precision | 0.87 | 12.25 | 5.8 | 1.11 |                                |

### ResNet50-Cifar
1卡，主要数据类型：FLOAT16，模型来源: ascend/ModelZoo-PyTorch。
主要算子为conv2d，每个step有51个, 因此对conv2d进行检测。
CV模型、依赖mmcv实现（如果不修改mmcv代码、工具无法获取step信息和反向信息）。

| 处理模式                     | 前/反向                 | 算子范围                 | 扰动方式 | 耗时（s） | 显存峰值（GB） | 耗时膨胀倍数 | 显存峰值膨胀倍数 | 备注                           |
|--------------------------------|-----------------------------------|-----------------|----------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|
| /        | /       | /           | /                 | 0.09      |  7.63         | 1            | 1                | 基线                   |
| check    | 前      | ["conv2d"]  | improve_precision | 0.889      | 7.94          |  9.81       |  1.04            |                                |
| fix      | 前      | ["conv2d"]  | improve_precision | 0.328      | 7.47          |  3.64       |  0.91            |                                |
| fix      | 前      | ["conv2d"]  | to_cpu            | 12.23      | 7.47          |  135.88     |  0.91              |                                |

### OpenSora1.0

4卡，主要数据类型：FLOAT16，模型来源: ascend/ModelZoo-PyTorch

每张卡每个step中linear算子个数为257个，FA算子个数为83（FA算子反向无效）。

| 处理模式                     | 前/反向                 | 算子范围                 | 扰动方式 | 耗时（s） | 显存峰值（GB） | 耗时膨胀倍数 | 显存峰值膨胀倍数 | 备注                           |
|--------------------------------|-----------------------------------|-----------------|----------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|--------------------------------|
| /        | /       | /           | /                 | 0.99 | 17.61 | 1            | 1                | 混精模式基线                   |
| check    | 前      | ["linear","npu_fusion_attention"] | improve_precision | 3.88 | 17.61 | 3.92 | 1 |                                |
| check | 前 | ["linear","npu_fusion_attention"] | add_noise | 3.46 | 17.61 | 3.49 | 1 | |
| check | 反 | ["linear"] | improve_precision | 12.61 | 17.61 | 12.74 | 1 | |
| check    | 反      | ["linear"]  | add_noise         | 9.8 | 17.61 | 9.90 | 1 |                                |
| fix      | 前      | ["linear"] | to_cpu            | 18.83 | 17.61 | 19.02 | 1 |                                |
| fix | 前 | ["linear"] | improve_precision | 2.83 | 17.61 | 2.86 | 1 | |
