{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b060e6",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Using Soundscapy for Binaural Recording Analysis\n",
    "\n",
    "Soundscapy has evolved to provide a comprehensive suite of acoustic and psychoacoustic analyses. This tutorial will guide you through using the new `AcousticAnalysis` class, which serves as the primary interface for performing these analyses. The system is optimized for batch processing, ease of use, and reproducibility.\n",
    "\n",
    "## Background\n",
    "\n",
    "Soundscapy relies on three main packages to provide its analysis functions:\n",
    "\n",
    "1. [Python Acoustics](https://github.com/python-acoustics/python-acoustics) (`acoustics`): Provides standard acoustic metrics with direct references to relevant standards.\n",
    "2. [scikit-maad](https://scikit-maad.github.io) (`maad`): Offers a suite of ecological soundscape and bioacoustic indices.\n",
    "3. [MoSQITo](https://github.com/Eomys/MoSQITo) (`mosqito`): Provides key psychoacoustic metrics.\n",
    "\n",
    "The metrics available include:\n",
    "- From Python Acoustics: $L_{Zeq}$, $L_{Aeq}$, $L_{Ceq}$, SEL, and associated statistics.\n",
    "- From scikit-maad: Temporal and spectral alpha indices.\n",
    "- From MoSQITo: Loudness, Sharpness, and Roughness.\n",
    "\n",
    "Soundscapy combines all of these metrics and makes it easy and (relatively) fast to compute any or all of them for a binaural audio recording. These results have been preliminarily confirmed through comparison of results obtained from Head Acoustics ArtemiS suite on a set of real-world recordings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c91ed01",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Getting Started\n",
    "\n",
    "Let's begin by importing the necessary modules and setting up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf0f9fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:32:50.418849Z",
     "start_time": "2024-08-23T23:32:49.610452Z"
    },
    "lines_to_next_cell": 2
   },
   "source": [
    "# imports\n",
    "from soundscapy import AudioAnalysis\n",
    "from soundscapy import AnalysisSettings\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "68fd3ee4",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Set up where the data is located. In this case, we'll use the sample recordings located under the `test` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f299664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:32:51.638232Z",
     "start_time": "2024-08-23T23:32:51.635123Z"
    }
   },
   "source": [
    "# May need to adjust for your system\n",
    "wav_folder = Path().cwd().parent.parent.joinpath(\"test\", \"data\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "556fc578",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Calibration Levels\n",
    "\n",
    "Ensuring correct calibration is crucial for accurate analysis. If you used equipment such as the Head Acoustics SqoBold, and were careful about how the recordings are exported to .wav, then they may already be correctly adjusted (as ours are here). However its best to be safe and calibrate each signal to their real-world dB level. To do this, we load in a .json that contains the per-channel correct dB $L_{eq}$ level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f78f14c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:32:52.348132Z",
     "start_time": "2024-08-23T23:32:52.342956Z"
    }
   },
   "source": [
    "levels_file = wav_folder.joinpath(\"Levels.json\")\n",
    "\n",
    "with open(levels_file) as f:\n",
    "    levels = json.load(f)\n",
    "\n",
    "# Look at the first five sets of levels\n",
    "list(levels.items())[:5]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e059d75091837b35",
   "metadata": {},
   "source": [
    "## Initializing AudioAnalysis\n",
    "\n",
    "The `AudioAnalysis` class is our main interface for performing acoustic analyses. Let's initialize it with default settings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bbd2c09e608b0b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:32:52.962550Z",
     "start_time": "2024-08-23T23:32:52.950928Z"
    }
   },
   "source": [
    "analysis = AudioAnalysis()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "52b6337863b0627f",
   "metadata": {},
   "source": [
    "By default, this loads the standard configuration. If you have a custom configuration file, you can specify it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d09ecda6a75758",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:32:53.496847Z",
     "start_time": "2024-08-23T23:32:53.495030Z"
    }
   },
   "source": [
    "# analysis = AudioAnalysis(\"path/to/custom_config.yaml\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "34481ae7",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Analyzing a Single File\n",
    "\n",
    "Let's analyze a single audio file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2fc0c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:35:51.679252Z",
     "start_time": "2024-08-23T23:32:54.114915Z"
    }
   },
   "source": [
    "binaural_wav = wav_folder.joinpath(\"CT101.wav\")\n",
    "decibel = (levels[\"CT101\"][\"Left\"], levels[\"CT101\"][\"Right\"])\n",
    "\n",
    "single_file_result = analysis.analyze_file(binaural_wav, calibration_levels=decibel)\n",
    "single_file_result"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d8eb14b26f30efb2",
   "metadata": {},
   "source": [
    "This performs all the analyses specified in our configuration on the single file. The `calibration_levels` parameter ensures that the analysis is calibrated correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72499085",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Batch Processing\n",
    "\n",
    "Now, let's analyze all the WAV files in our folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b72c2220552404",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:39:37.352229Z",
     "start_time": "2024-08-23T23:35:51.680088Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip_execution"
    ]
   },
   "source": [
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "folder_results = analysis.analyze_folder(wav_folder, calibration_file=levels_file)\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f\"Time taken: {end-start:.2f} seconds\")\n",
    "folder_results\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6b053ebc92c2aab1",
   "metadata": {},
   "source": [
    "Note: You may receive numerous `DeprecationWarnings` from `acoustics` or `numpy`. This is expected at this stage and is nothing to do with Soundscapy. The Python Acoustics package has been archived and is no longer being maintained and as such it has some non-critical bugs and out-of-date code. Along with a developer at UGE, I am a maintainer on a package called `acoustic-toolbox` which is taking over from Python Acoustics. As soon as possible, Soundscapy will be switching over to this new package which will solve these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d816f95361ca52d4",
   "metadata": {},
   "source": [
    "### Saving Results\n",
    "\n",
    "We can easily save our results to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa51eb7d902cdf59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:39:37.391763Z",
     "start_time": "2024-08-23T23:39:37.353326Z"
    },
    "tags": [
     "skip-execution"
    ]
   },
   "source": [
    "analysis.save_results(folder_results, \"acoustic_analysis_results.xlsx\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d7f1db58370a42f1",
   "metadata": {},
   "source": [
    "## Customizing the Analysis\n",
    "\n",
    "### Updating Configuration\n",
    "\n",
    "If we want to modify our analysis configuration, we can do so using the `update_config` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0aa45e30d4528df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:39:37.395225Z",
     "start_time": "2024-08-23T23:39:37.392960Z"
    }
   },
   "source": [
    "new_config = {\n",
    "    \"PythonAcoustics\": {\n",
    "        \"LAeq\": {\n",
    "            \"run\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "analysis.update_config(new_config)\n",
    "print(\"Configuration updated\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c32ce9d62416e186",
   "metadata": {},
   "source": [
    "This would disable the LAeq analysis in subsequent runs.\n",
    "\n",
    "### Saving the Updated Configuration\n",
    "\n",
    "We can save the updated configuration to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea060184a6e8ed48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:39:37.400053Z",
     "start_time": "2024-08-23T23:39:37.395870Z"
    }
   },
   "source": [
    "analysis.save_config(\"updated_config.yaml\")\n",
    "print(\"Updated configuration saved to 'updated_config.yaml'\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "49c08308e30cd87a",
   "metadata": {},
   "source": [
    "Of course, you could also directly edit your config.yaml file instead.\n",
    "\n",
    "## Advanced Usage\n",
    "\n",
    "### Custom Analysis Settings\n",
    "\n",
    "For more control, we can create a custom `AnalysisSettings`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "416f065a65dd3059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T23:40:28.264823Z",
     "start_time": "2024-08-23T23:40:28.245755Z"
    }
   },
   "source": [
    "custom_settings = AnalysisSettings.from_yaml(\"example_settings.yaml\")\n",
    "custom_settings.update_setting(\"scikit_maad\", \"all_temporal_alpha_indices\", run=True)\n",
    "custom_settings.update_setting(\"scikit_maad\", \"all_spectral_alpha_indices\", run=True)\n",
    "\n",
    "# Create a new AudioAnalysis instance with the custom settings\n",
    "custom_analysis = AudioAnalysis(config_path=\"example_settings.yaml\")\n",
    "\n",
    "# Or update an existing instance\n",
    "analysis.update_config(custom_settings.model_dump())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6798e48e59ab6f8f",
   "metadata": {},
   "source": [
    "## Parallel Processing Control\n",
    "\n",
    "The `analyze_folder` method uses parallel processing by default. You can control the number of worker processes using the `max_workers` argument. Setting `max_workers = None` (the default) will use all available CPU cores. Setting `max_workers = 1` will disable parallel processing, and will take significantly longer to process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6484fc1a622df8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T00:11:18.020614Z",
     "start_time": "2024-08-23T23:46:57.800099Z"
    },
    "tags": [
     "skip-execution"
    ]
   },
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "serial_analysis = AudioAnalysis()\n",
    "folder_results = serial_analysis.analyze_folder(wav_folder, calibration_file=levels_file, max_workers=1)\n",
    "\n",
    "end = time.perf_counter()\n",
    "\n",
    "print(f\"Time taken: {end-start:.2f} seconds\")\n",
    "folder_results"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2fc10586dec52c1a",
   "metadata": {},
   "source": [
    "As we can see, on my system, enabling parallel processing reduces the processing time for these 8 files from almost 25 minutes to less than 4 minutes. This will vary depending on your system and the number of files you are processing. The more CPU cores and the more files, the more beneficial parallel processing will be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22666da2c431e3a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The `AudioAnalysis` class provides a powerful and flexible interface for performing acoustic and psychoacoustic analyses on binaural recordings. It simplifies the process of batch analysis, configuration management, and result handling, making it easier to process large datasets consistently and efficiently.\n",
    "\n",
    "Remember that the specific metrics calculated and their settings are determined by the configuration. Always ensure your configuration accurately reflects your analysis needs, keep in mind that the psychoacoustic analyses in MoSQITo can be computationally intensive, and don't hesitate to customize it for your specific research or application requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f1d664dc371cbc",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_markers": "\"\"\""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "839cba8ae7f7082c5bcb3c590fd12f2b3a15a875e42d2935e5155aa711605eac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
