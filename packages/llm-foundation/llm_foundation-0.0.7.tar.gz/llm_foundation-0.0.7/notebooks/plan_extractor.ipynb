{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 01:32:00 fperez-gcloud-stupid-sailor-twift root[1541729] INFO Logger root configured\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to configure logger root in module llm_foundation\n",
      "root # of associated handlers - 0\n",
      "Logging is not configured yet. Configuring it now.\n",
      "Basic logging config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 01:32:01 fperez-gcloud-stupid-sailor-twift langchain_community.utils.user_agent[1541729] WARNING USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from llm_foundation import logger\n",
    "from llm_foundation.basic_structs import Provider, LMConfig\n",
    "from llm_foundation.extractors import PlanExtractor, Plan, MultiTreePlan, Step\n",
    "from llm_foundation.lm import get_model_catalog, get_lm\n",
    "from llm_foundation.routing import ToolMaster\n",
    "from llm_foundation.utils import banner, show_banner\n",
    "from langchain.agents.output_parsers.tools import ToolsAgentOutputParser\n",
    "from typing import Union, List, Dict, Any\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 01:32:01 fperez-gcloud-stupid-sailor-twift root[1541729] INFO Creating lm object for provider LC\n",
      "2024-08-28 01:32:01 fperez-gcloud-stupid-sailor-twift root[1541729] INFO Creating ModelType.Chat object for model gpt-4o-mini\n",
      "2024-08-28 01:32:01 fperez-gcloud-stupid-sailor-twift root[1541729] INFO LM object client=<openai.resources.chat.completions.Completions object at 0x7f6dc5b5c650> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f6dc5b5db20> root_client=<openai.OpenAI object at 0x7f6dc5e485c0> root_async_client=<openai.AsyncOpenAI object at 0x7f6dc5b5c680> model_name='gpt-4o-mini' temperature=0.0 openai_api_key=SecretStr('**********') openai_proxy='' max_tokens=300 created\n"
     ]
    }
   ],
   "source": [
    "lm_config = LMConfig(model=\"gpt-4o-mini\", provider=Provider.LC)\n",
    "lm = get_lm(lm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "extract\n",
      "Extracts from the text passed an itemized list of plan steps as text.\n",
      "{'text': {'title': 'Text', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "plan = \"\"\"\"\n",
    "Thought: To determine the combined weight of a Toy Poodle and a Scottish Terrier, I need to find the average weight of each breed and then sum them up.\n",
    "\n",
    "Plan:\n",
    "1. Find the average weight of a Toy Poodle.\n",
    "2. Find the average weight of a Scottish Terrier.\n",
    "3. Sum the average weights of both breeds to get the combined weight.\n",
    "\n",
    "Let's proceed with the plan.\n",
    "\"\"\"\n",
    "\n",
    "plan_extractor_tool = PlanExtractor.build_tool(lm, Plan, use_pydantic_output=False)\n",
    "\n",
    "print(type(plan_extractor_tool))\n",
    "print(plan_extractor_tool.name)\n",
    "print(plan_extractor_tool.description)\n",
    "print(plan_extractor_tool.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [plan_extractor_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query without tools\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 01:32:02 fperez-gcloud-stupid-sailor-twift httpx[1541729] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='12 * 4 = 48.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 13, 'total_tokens': 21}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None} id='run-cddcb1af-0c92-4bcc-8973-b32b2c025bcb-0' usage_metadata={'input_tokens': 13, 'output_tokens': 8, 'total_tokens': 21}\n",
      "\n",
      "Query with tools\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 01:32:04 fperez-gcloud-stupid-sailor-twift httpx[1541729] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_LVoVWuM0ANsSSxRJlWAGf0V1', 'function': {'arguments': '{\"text\":\"Thought: To determine the combined weight of a Toy Poodle and a Scottish Terrier, I need to find the average weight of each breed and then sum them up.\\\\n\\\\nPlan:\\\\n1. Find the average weight of a Toy Poodle.\\\\n2. Find the average weight of a Scottish Terrier.\\\\n3. Sum the average weights of both breeds to get the combined weight.\\\\n\\\\nLet\\'s proceed with the plan.\"}', 'name': 'extract'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 144, 'total_tokens': 242}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_9722793223', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-c7658567-9f27-49e1-b353-ad324ea59565-0' tool_calls=[{'name': 'extract', 'args': {'text': \"Thought: To determine the combined weight of a Toy Poodle and a Scottish Terrier, I need to find the average weight of each breed and then sum them up.\\n\\nPlan:\\n1. Find the average weight of a Toy Poodle.\\n2. Find the average weight of a Scottish Terrier.\\n3. Sum the average weights of both breeds to get the combined weight.\\n\\nLet's proceed with the plan.\"}, 'id': 'call_LVoVWuM0ANsSSxRJlWAGf0V1', 'type': 'tool_call'}] usage_metadata={'input_tokens': 144, 'output_tokens': 98, 'total_tokens': 242}\n",
      "\n",
      "Query with tools with tools output parser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 01:32:06 fperez-gcloud-stupid-sailor-twift httpx[1541729] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ToolAgentAction(tool='extract', tool_input={'text': \"Thought: To determine the combined weight of a Toy Poodle and a Scottish Terrier, I need to find the average weight of each breed and then sum them up.\\n\\nPlan:\\n1. Find the average weight of a Toy Poodle.\\n2. Find the average weight of a Scottish Terrier.\\n3. Sum the average weights of both breeds to get the combined weight.\\n\\nLet's proceed with the plan.\"}, log='\\nInvoking: `extract` with `{\\'text\\': \"Thought: To determine the combined weight of a Toy Poodle and a Scottish Terrier, I need to find the average weight of each breed and then sum them up.\\\\n\\\\nPlan:\\\\n1. Find the average weight of a Toy Poodle.\\\\n2. Find the average weight of a Scottish Terrier.\\\\n3. Sum the average weights of both breeds to get the combined weight.\\\\n\\\\nLet\\'s proceed with the plan.\"}`\\n\\n\\n', message_log=[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_jIhEAw5ebd12RQXRNwpLnaKE', 'function': {'arguments': '{\"text\":\"Thought: To determine the combined weight of a Toy Poodle and a Scottish Terrier, I need to find the average weight of each breed and then sum them up.\\\\n\\\\nPlan:\\\\n1. Find the average weight of a Toy Poodle.\\\\n2. Find the average weight of a Scottish Terrier.\\\\n3. Sum the average weights of both breeds to get the combined weight.\\\\n\\\\nLet\\'s proceed with the plan.\"}', 'name': 'extract'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 144, 'total_tokens': 242}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1cfa61ab-d2b5-4674-aa6d-11f114ad5d9d-0', tool_calls=[{'name': 'extract', 'args': {'text': \"Thought: To determine the combined weight of a Toy Poodle and a Scottish Terrier, I need to find the average weight of each breed and then sum them up.\\n\\nPlan:\\n1. Find the average weight of a Toy Poodle.\\n2. Find the average weight of a Scottish Terrier.\\n3. Sum the average weights of both breeds to get the combined weight.\\n\\nLet's proceed with the plan.\"}, 'id': 'call_jIhEAw5ebd12RQXRNwpLnaKE', 'type': 'tool_call'}], usage_metadata={'input_tokens': 144, 'output_tokens': 98, 'total_tokens': 242})], tool_call_id='call_jIhEAw5ebd12RQXRNwpLnaKE')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query = \"calculate 12 * 4\"\n",
    "query_requiring_tools = f\"extract the plan from {plan}\"\n",
    "\n",
    "print(\"\\nQuery without tools\")\n",
    "print(lm.invoke(query))\n",
    "\n",
    "lm_with_tools = lm.bind_tools(tools)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "print(\"\\nQuery with tools\")\n",
    "chain = prompt | lm_with_tools # | ToolsAgentOutputParser()\n",
    "chain_response = chain.invoke({\"input\": query_requiring_tools})\n",
    "print(type(chain_response))\n",
    "print(chain_response)\n",
    "\n",
    "print(\"\\nQuery with tools with tools output parser\")\n",
    "chain = prompt | lm_with_tools |ToolsAgentOutputParser()\n",
    "chain.invoke({\"input\": query_requiring_tools})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_master = ToolMaster(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 01:32:08 fperez-gcloud-stupid-sailor-twift httpx[1541729] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-08-28 01:32:08 fperez-gcloud-stupid-sailor-twift root[1541729] INFO ========================================================================================================================\n",
      "2024-08-28 01:32:08 fperez-gcloud-stupid-sailor-twift root[1541729] INFO =                                                      Call Tool                                                       =\n",
      "2024-08-28 01:32:08 fperez-gcloud-stupid-sailor-twift root[1541729] INFO ========================================================================================================================\n",
      "2024-08-28 01:32:08 fperez-gcloud-stupid-sailor-twift root[1541729] INFO Extracting <class 'llm_foundation.extractors.Plan'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type plan: <class 'llm_foundation.extractors.Plan'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 01:32:09 fperez-gcloud-stupid-sailor-twift httpx[1541729] INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-08-28 01:32:09 fperez-gcloud-stupid-sailor-twift root[1541729] INFO Response (<class 'dict'>): {'plan': [{'id': '1', 'description': 'Find the average weight of a Toy Poodle.', 'dependend_steps': ['3'], 'depending_steps': []}, {'id': '2', 'description': 'Find the average weight of a Scottish Terrier.', 'dependend_steps': ['3'], 'depending_steps': []}, {'id': '3', 'description': 'Sum the average weights of both breeds to get the combined weight.', 'dependend_steps': [], 'depending_steps': ['1', '2']}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('call_HeZotnjhcRiuzYMSXH05KU2I',\n",
       "  'extract',\n",
       "  {'plan': [{'id': '1',\n",
       "     'description': 'Find the average weight of a Toy Poodle.',\n",
       "     'dependend_steps': ['3'],\n",
       "     'depending_steps': []},\n",
       "    {'id': '2',\n",
       "     'description': 'Find the average weight of a Scottish Terrier.',\n",
       "     'dependend_steps': ['3'],\n",
       "     'depending_steps': []},\n",
       "    {'id': '3',\n",
       "     'description': 'Sum the average weights of both breeds to get the combined weight.',\n",
       "     'dependend_steps': [],\n",
       "     'depending_steps': ['1', '2']}]})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chain = prompt | lm_with_tools | tool_master\n",
    "chain_response = new_chain.invoke({\"input\": query_requiring_tools})\n",
    "chain_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan': [{'id': '1', 'description': 'Find the average weight of a Toy Poodle.', 'dependend_steps': ['3'], 'depending_steps': []}, {'id': '2', 'description': 'Find the average weight of a Scottish Terrier.', 'dependend_steps': ['3'], 'depending_steps': []}, {'id': '3', 'description': 'Sum the average weights of both breeds to get the combined weight.', 'dependend_steps': [], 'depending_steps': ['1', '2']}]}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(chain_response[0][2])\n",
    "print(type(chain_response[0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan': [{'id': '1', 'description': 'Find the average weight of a Toy Poodle.', 'dependend_steps': ['3'], 'depending_steps': []}, {'id': '2', 'description': 'Find the average weight of a Scottish Terrier.', 'dependend_steps': ['3'], 'depending_steps': []}, {'id': '3', 'description': 'Sum the average weights of both breeds to get the combined weight.', 'dependend_steps': [], 'depending_steps': ['1', '2']}]}\n"
     ]
    }
   ],
   "source": [
    "plan_data = chain_response[0][2]\n",
    "print(plan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_tree = PlanExtractor.build_multi_tree_plan(plan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Step(id='1', description='Find the average weight of a Toy Poodle.', dependend_steps=['3'], depending_steps=[]),\n",
       " Step(id='2', description='Find the average weight of a Scottish Terrier.', dependend_steps=['3'], depending_steps=[]),\n",
       " Step(id='3', description='Sum the average weights of both breeds to get the combined weight.', dependend_steps=[], depending_steps=[Step(id='1', description='Find the average weight of a Toy Poodle.', dependend_steps=['3'], depending_steps=[]), Step(id='2', description='Find the average weight of a Scottish Terrier.', dependend_steps=['3'], depending_steps=[])])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_tree.traverse_leafs_first_dependants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "multi_tree.traverse_depth_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "multi_tree.traverse_breadth_first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "5 validation errors for Plan\nplan -> 0 -> dependend_steps\n  field required (type=value_error.missing)\nplan -> 1 -> dependend_steps\n  field required (type=value_error.missing)\nplan -> 2 -> dependend_steps\n  field required (type=value_error.missing)\nplan -> 3 -> dependend_steps\n  field required (type=value_error.missing)\nplan -> 4 -> dependend_steps\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m      2\u001b[0m pydantic_json_plan \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m{\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplan\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m}\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     13\u001b[0m json_plan\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mloads(pydantic_json_plan)\n\u001b[0;32m---> 14\u001b[0m fake_multi_tree \u001b[38;5;241m=\u001b[39m \u001b[43mPlanExtractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_multi_tree_plan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_plan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m fake_multi_tree\u001b[38;5;241m.\u001b[39mtraverse_leafs_first_dependants()\n",
      "File \u001b[0;32m~/dev/llm_base/llm_foundation/extractors.py:237\u001b[0m, in \u001b[0;36mPlanExtractor.build_multi_tree_plan\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_multi_tree_plan\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data: Union[\u001b[38;5;28mdict\u001b[39m, Plan]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m MultiTreePlan:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Convert json object to Plan\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 237\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mPlan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     id_to_step \u001b[38;5;241m=\u001b[39m {step\u001b[38;5;241m.\u001b[39mid: step \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mplan}\n\u001b[1;32m    240\u001b[0m     child_to_parents \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[0;32m~/dev/llm_base/.pixi/envs/default/lib/python3.12/site-packages/pydantic/v1/main.py:526\u001b[0m, in \u001b[0;36mBaseModel.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m    524\u001b[0m         exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m expected dict not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ValidationError([ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY)], \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/llm_base/.pixi/envs/default/lib/python3.12/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 5 validation errors for Plan\nplan -> 0 -> dependend_steps\n  field required (type=value_error.missing)\nplan -> 1 -> dependend_steps\n  field required (type=value_error.missing)\nplan -> 2 -> dependend_steps\n  field required (type=value_error.missing)\nplan -> 3 -> dependend_steps\n  field required (type=value_error.missing)\nplan -> 4 -> dependend_steps\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "pydantic_json_plan = '''\n",
    "{\n",
    "    \"plan\": [\n",
    "        {\"id\": \"1\", \"description\": \"Task 1\", \"dependent_steps\": [], \"depending_steps\": [\"2\", \"3\"]},\n",
    "        {\"id\": \"2\", \"description\": \"Task 2\", \"dependent_steps\": [\"1\", \"5\"], \"depending_steps\": [\"4\"]},\n",
    "        {\"id\": \"3\", \"description\": \"Task 3\", \"dependent_steps\": [\"1\"], \"depending_steps\": []},\n",
    "        {\"id\": \"4\", \"description\": \"Task 4\", \"dependent_steps\": [\"2\"], \"depending_steps\": []},\n",
    "        {\"id\": \"5\", \"description\": \"Task 5\", \"dependent_steps\": [], \"depending_steps\": [\"2\"]}\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "json_plan=json.loads(pydantic_json_plan)\n",
    "fake_multi_tree = PlanExtractor.build_multi_tree_plan(json_plan)\n",
    "\n",
    "fake_multi_tree.traverse_leafs_first_dependants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fake_multi_tree.traverse_depth_first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_multi_tree.traverse_breadth_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
