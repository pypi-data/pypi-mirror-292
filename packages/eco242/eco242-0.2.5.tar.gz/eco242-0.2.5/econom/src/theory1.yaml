num1:
    text: |-
        ### **1)** Линейная модель множественной регрессии. Основные предпосылки метода наименьших квадратов**.**

        Линейная модель линейной связи – это уравнение связи с несколькими переменными  $y = f(x_1, x_2, ... x_n) + ξ$ , где y – зависимая переменная, $x_n$  – независимая переменная. $y = a_0 + a_1x_1+...+a_nx_n$  – формула линейной множественной регрессии, где   – это параметры, которые вычисляются разными способами, один из них – метод наименьших квадратов.

        Также данная модель может записываться в матричном виде Y = XB+E, где Y – столбец зависимых переменных, X – матрица факторов, B – вектор коэффициентов, Е – вектор случайных ошибок. В данном случае коэффициенты матрицы B так же могут вычисляться с помощью МНК.

        МНК - математический метод, применяемый для решения различных задач, основанный на минимизации суммы квадратов отклонений некоторых функций от экспериментальных входных данных.

        Предпосылки:

        1. *Математическое ожидание случайного отклонения ε равно нулю: Е(ε)=0 для всех наблюдений*
        2. *Дисперсия случайных отклонений ε постоянна:*  *для любых наблюдений i и j (гомоскедастичность)*
        3. *Случайные отклонения $\varepsilon_i$ и $\varepsilon_j$ ( $i \neq j$) не коррелируют между собой (отсутствие автокорреляции). $E(\varepsilon_i, \varepsilon_j ) = 0, i \neq j$*
        4. *Случайные отклонения должны быть статистически независимы (некоррелированы) от объясняющих переменных.*
        5. *Отсутствие мультиколлинеарности. Между объясняющий переменными отсутствует сильная линейная зависимость.*
        6. *Возмущения $\varepsilon_i$ нормально распределены $\varepsilon_i \sim N(0; \sigma^2)$.*

        Если регрессионная модель удовлетворяет условиям Гаусса-Маркова, ее параметры обладают свойствами несмещенности, эффективности и состоятельности.

        Оценки в матричном виде могут быть рассчитаны по как $B=(X^TX)^{-1}X^TY$

        Если уравнение представлено не матрицей, коэффициенты рассчитываются из системы производных по каждому коэффициенту.
    keywords: [1, линейная, множественной регрессии, предпосылки, наименьших квадратов]
num2:
    text: |-
        ### **2)** Нелинейные модели регрессии. Походы к оцениванию. Примеры

        Различают два класса нелинейной регрессии:

        1. Нелинейные по переменным, но линейные по параметрам. Примеры: полиномы > 1 степени, гиперболы. Например, полиномиальная модель: $y = \beta_0 + \beta_1x + \beta_2x^2 + … + \beta_m*x^m + \varepsilon$
        2. Нелинейные по параметрам но линейные по переменным. Примеры: Степенные, показательные функции. Например, степенная модель: $y = \beta_0*x_1^{\beta_1} * x_2^{\beta_2} * … x_m^{\beta_m}\varepsilon$
        Так как классическая модель регрессии предполагает линейный характер зависимости переменных Y и X, то перед применением МНК для оценки, нелинейные модели по параметрам линеаризовывают, это делается путём логарифмирования правой и левой части. Нелинейные по переменным же модели требуют добавления новых объясняющих переменных соответсвующим образом преобразованных. Для оценки параметров нелинейных моделей используют два подхода: Первый подход основан на линеаризации модели и заключается в том, что с помощью подходящих преобразований исходных переменных исследуемую нелинейную зависимость представляют в виде линейной между преобразованными переменными. Второй подход, основанный на применении методов нелинейной оптимизации, применяется в том случає, когда подобрать соответствующее преобразование не удается.

        Например: полиномиальная модель m-го порядка может быть приведена к линейному виду путем замены переменных $x^j = x_j^{\prime}$. После замены переменных получим линейную регрессионную модель вида $y = \beta_0 + \sigma_{j=1}^m \beta_jx_j^{\prime} + \varepsilon$
        К классу степенных функций относятся кривые спроса и предложения, производственные функции и тд. Например, производственная функция Кобба-Дугласа $Y = AK^{\alpha}L^{\beta}\varepsilon$
    keywords: [2, нелинейные, подходы к оцениванию ]
num3:
    text: |-
        ### **3)** Тестирование правильности выбора спецификации: типичные ошибки спецификации модели, Тест Рамсея (тест RESET), условия применения теста.

        Типичные ошибки:

        1. Неверно выбран тип уравнения регрессии
        2. В линейное уравнение множественной регрессии включен несущественный регрессор
        3. В линейное уравнение множественной регрессии не включен существенный регрессор

        Тест Рамсея:
        RESET – тест Рамсея отвечает на вопрос, надо ли включать в регрессию степени независимых переменных (идея заключается в том, что добавление нелинейных функций $\hat Y$ не должно улучшать наших знаний относительно Y)
        Условие применения: модель - линейное уравнение множественной регрессии

        $H_0:$ спецификация модели является правильной

        $H_1:$ спецификация неправильная (не включён существенный признак)

        Для проверки сначала оценивается исходная модель, далее заново оценивается эта же модель но с добавлением вычисленных на предыдущем этапе предсказываемых значений в степени p (обычно не большой). Далее происходит оценка модели через F статистику, если она больше критического значения, значит отсутствует важный признак в модели.

        $F_{набл} = \frac{\frac{(ESS_1 - ESS_2}{p}}{\frac{ESS_2}{n-m-p}} \sim F_{крит} (p, n-m-p), 
        F_{набл} \gt F_{крит} (p, n-m-p)$
    keywords: [спецификации, Рамсея]
num4:
    text: |-
        ### **4)** Тестирование правильности выбора спецификации: типичные ошибки спецификации модели, Критерий Акаике, Критерий Шварца. условия применения критериев.

        Типичные ошибки:

        1. Неверно выбран тип уравнения регрессии
        2. В линейное уравнение множественной регрессии включен несущественный регрессор
        3. В линейное уравнение множественной регрессии не включен существенный регрессор

        AIC позволяет сравнивать несколько статистических моделей друг с другом для того, чтобы определить, какая из моделей лучше соответствует данным. Особенностью критерия является введение штрафа за число параметров модели.
        Статистика рассчитывается как: $AIC = ln(\frac{ESS_k}{n})+\frac{2k}{n}+1+ln(2\pi)$. При увеличении объясняющих переменных первое слагаемое в правой части уменьшается, второе – увеличивается.

        BIC - мера относительного качества моделей, учитывающая степень «подгонки» модели под данные со штрафом на используемое количество оцениваемых параметров. То есть критерий основаны на неком компромиссе между точностью и сложностью модели.

        Статистика: $BIC = ln(\frac{ESS_k}{n})+\frac{kln(n)}{n}+1+ln(2\pi)$*.* При увеличении количества объясняющих переменных первое слагаемое в правой части уменьшается, а второе – увеличивается.

        В обоих случаях предпочтение отдаётся тем моделям, где данные статистики меньше. Различаются они способом оценки баланса между переменными и ESS.

        Условия применения критериев:
        1. Сравниваемые модели построены на одном и том же наборе данных.
        2. Сравниваемые модели имеют одну и ту же объясняемую переменную.
        3. Обучающая выборка имеет бесконечный размер.
    keywords: [Акаике, Шварца]
num5:
    text: |-
        ### **5)** Гетероскедастичность: определение, причины, последствия. Тест Голдфеда-Квандта и особенности его применения.

        Гетероскедастичностью называется зависимость дисперсии возмущения от периода наблюдений, т.е. $\sigma^2_{e_i} \ne \sigma^2_{e_j} \ne const$ для любых i и j.

        Причины:
        1. Эффект масштаба в пространственно-временных данных
        2. Эффект запаздывания информации
        3. Неоднородность исследуемых данных.

        Последствия:
        - Оценки параметров b не будут эффективными, особенно при малых выборках
        - Стандартные ошибки параметров $m_{b_j}$ будут рассчитываться со смещением
        - Оценки t и F статистики будут ненадёжными.

        Тест Голфеда-Квандта:
        $H_0$: Присутствует гомоскедастичность
        $H_1$: Присутствует гетероскедастичность

        1. Выборочные данные упорядочиваются по величине модуля регрессора, относительно которого есть подозрение на гетероскедастичность
        2. Выборка делится на 3 группы, где $n_1 = n_3, k <n_1<\frac{n}{2}$, k – число параметров, n – общая выборка
        3. Далее оцениваются две вспомогательные регрессии по 1 и 3 группе по которым вычисляются суммы квадратов остатков $ESS_1, ESS_3$
        4. Далее вычисляются статистики $GQ=\frac{ESS_1}{ESS_3}, GQ^{-1}=\frac{ESS_3}{ESS_1}$
        5. Определяется F распределение $F(\alpha, n_1-k, n_1-k)$
        6. Если $GQ \le F_{кр}$ и $GQ^{-1} \le F_{кр}$ то присутствует гомоскедастичность
        Данный тест применяется при маленьких выборках и нормально распределённых остатках, которые не коррелируют друг с другом, cтандартные отклонения $\sigma^2_{e_i} $пропорциональны значениям $x_i$.
    keywords: [Гетероскедостичность, Голдфеда-Квандта]
num6:
    text: |-
        ### **6)** Гетероскедастичность: определение, причины, последствия. Тест ранговой корреляции Спирмена и особенности его применения.

        Гетероскедастичностью называется зависимость дисперсии возмущения от периода наблюдений, т.е. $\sigma^2_{e_i} \ne \sigma^2_{e_j} \ne const$ для любых i и j.

        Причины:
        1. Эффект масштаба в пространственно-временных данных
        2. Эффект запаздывания информации
        3. Неоднородность исследуемых данных.

        Последствия:
        - Оценки параметров b не будут эффективными, особенно при малых выборках
        - Стандартные ошибки параметров $m_{b_j}$будут рассчитываться со смещением
        - Оценки t и F статистики будут ненадёжными.

        Тест Спирмена:
        $H_0$: Присутствует гомоскедастичность
        $H_1$: Присутствует гетероскедастичность
        1. Рассчитываются абсолютные значения остатков модели
        2. Остатки и значения фактора ранжируются (определяются их ранги)
        3. Рассчитывается ранговое значение $D^2_i = (D_x + D_e)^2$ и вычисляется сумма всех этих квадратов
        4. Далее определяется коэффициент ранговой корреляции $r = 1 - \dfrac{6\sum_{i=1}^nD^2_i}{n(n^2 -1)}$
        5. Определяется критическое значение по Стьюденту t(a, n-2)
        6. Вычисляется t статистика $t = \dfrac{r\sqrt{n-2}}{\sqrt{1-r^2}} *\sqrt{n-2}$
        7. Если t < tкр (a=0,05; n=2), то гомоскедастичность, иначе гетеро
        Данный тест рекомендуется использовать при равномерном распределении измененяемой величины.
    keywords: [Гетероскедостичность, Спирмена]
num7:
    text: |-
        ### **7)** Гетероскедастичность: определение, причины, последствия. Тест Тест Бреуша-Пагана и особенности его применения.

        Гетероскедастичностью называется зависимость дисперсии возмущения от периода наблюдений, т.е. $\sigma^2_{e_i} \ne \sigma^2_{e_j} \ne const$ для любых i и j.

        Причины:
        1. Эффект масштаба в пространственно-временных данных
        2. Эффект запаздывания информации
        3. Неоднородность исследуемых данных.

        Последствия:
        - Оценки параметров b не будут эффективными, особенно при малых выборках
        - Стандартные ошибки параметров $m_{b_j}$будут рассчитываться со смещением
        - Оценки t и F статистики будут ненадёжными.

        Тест Бреуша-Пагана:
        $H_0$: Присутствует гомоскедастичность
        $H_1$: Присутствует гетероскедастичность
        1. Рассчитываем обычную регрессию через МНК и вычисляем остатки, квадраты остатков
        2. Оценка дисперсии возмущений $\hat \sigma^2 = \dfrac{\sum_{t=1}^ne^2_t}{n}$
        3. Оценивается новая регрессия вида $\dfrac{e^2_t}{\hat \sigma_t^2} = \gamma_0 + Z_t^T \cdot \gamma +v_t$ и находится RSS
        4. Вычисляется статистика $BP=\dfrac{RSS}{2}$
        5. Если $BP < \chi^2(k)$, то гомоскедастичность, иначе гетеро
        Данный метод чаще всего использую при больших выборках
    keywords: [Гетероскедастичность,Бреуша-Пагана]
num8:
    text: |-
        ### **8)** Гетероскедастичность: определение, причины, последствия. Тест Глейзера и особенности его применения.

        Гетероскедастичностью называется зависимость дисперсии возмущения от периода наблюдений, т.е. $\sigma^2_{e_i} \ne \sigma^2_{e_j} \ne const$ для любых i и j.

        Причины:
        1. Эффект масштаба в пространственно-временных данных
        2. Эффект запаздывания информации
        3. Неоднородность исследуемых данных.

        Последствия:
        - Оценки параметров b не будут эффективными, особенно при малых выборках
        - Стандартные ошибки параметров $m_{b_j}$будут рассчитываться со смещением
        - Оценки t и F статистики будут ненадёжными.

        Тест Глейзера:
        $\sigma_i = a_0 + a_1*x_i^{\gamma} +w_i$

        $H_0$: Присутствует гомоскедастичность (a_1=0)

        $H_1$: Присутствует гетероскедастичность $(a1 \neq 0)$

        1. Вычисляем абсолютные значения остатков для обычной модели при МНК
        2. Определяем $t_{кр} = t(\alpha, n-2)$
        3. Строим МНК оценки для моделей $|\varepsilon_i|=a_0 +a_1 \cdot x_i^{\gamma}$, для $\gamma$ от -1 до 1 с шагом 0.5, если хотя бы для одной модели t статистика a1 оказалась значимость, значит есть гетероскедастичность, иначе нет

        Данный тест способен не только выявить гетероскедастичность, но и конкретный вид зависимости этих остатков от каждой независимой переменной
    keywords: [Гетероскедастичность, Глейзера]
num9:
    text: |-
        ### **9)** Способы корректировки гетероскедастичности: взвешенный метод наименьших квадратов (ВМНК) и особенности его применения.

        Способы:
        1. Взвешенный метод наименьших квадратов (ВМНК)
        2. Доступный взвешенный метод наименьших квадратов (ДВМНК)
        3. Обобщённый метод наименьших квадратов (ОМНК)

        Перечисленные методы нацелены на преобразование переменных таким образом, чтобы в спецификации преобразованной модели случайное возмущение удовлетворяло предпосылкам Гаусса-Маркова

        ВМНК:
        Применяется, если бы нам были известны дисперсии всех ошибок.

        Правая и левая часть уравнения регрессии $y_i = \beta_0 + \beta_1*x_i + \varepsilon_i$ делятся на известное $\sigma_i$. 

        Модель примет вид:
        $$
        \dfrac{Y_i}{\sigma_i}=\beta_0 \dfrac{1}{\sigma_i} + \beta_1 \dfrac{X_{2i}}{\sigma_i}+...+\beta_k \dfrac{X_{ki}}{\sigma_i}+\dfrac{u_i}{\sigma_i}
        $$

        Её можно привести к обычному линейному виду заменив новые коэффициенты:
        $$
        Y^*_i=\beta_0 z_i + \beta_1 X^*_{2i}+...+\beta_kX^*_{ki}+u^*_{i}  
        $$

        Данный вектор случайных отклонений $u_i^*$ удовлетворяет условию гомоскедастичности.
        В случае неизвестных дисперсий положим $\sigma_i = \sqrt{X_i}$ и проделаем всё то же самое
    keywords: [корректировки гетероскедастичности, ВМНК] 
num10:
    text: |-
        ### **10) Автокорреляция: определение, причины, последствия. Тест Дарбина-Уотсона и особенности его применения.**

        Автокорреляция – это наличие сильной корреляционной зависимости между последовательными уровнями ряда динамики.

        Автокорреляция — это понятие математической статистики, которое характеризует степень статистической взаимосвязи между элементами данных одного временного ряда.

        **Причинами автокорреляции являются:**
        - ошибки спецификации модели (пропуск важной объясняющей переменной, использование ошибочной функциональной зависимости между переменными);
        - ошибки измерений*;*
        - характер наблюдений (например, данные временных рядов).
        - Инертность экономических показателей
        - The Cobweb effect (паутинообразный эффект) (во многих отраслях производства экономические показатели реагируют на изменение экономических условий с запаздыванием);
        - «Манипулирование данными». Сглаживание данных.

        **Последствия автокорреляции:**
        - Хотя оценки МНК коэффициентов регрессии останутся несмещенными, они уже не будут эффективными
        - Оценки МНК для стандартных отклонений коэффициентов регрессии будут смещенными, чаще всего вниз, т.е будут заниженными.
        - Статистики t и F будут неадекватными. Следствием заниженности оценок стандартных отклонений коэффициентов является завышенность t – статистик.

        **Тест Дарбина-Уотсона:**
        $H_0$: между остатками нет корреляции.

        $H_1$: остатки автокоррелированы.

        Формула для вычисления статистики Дарбина-Уотсона **DW** по остаткам регрессии:
        $$
        DW = \frac {\sum_{t=2}^{n}(e_t - e_{t-1})^2}{\sum_{t=1}^{n}e_t^2} 
        $$

        **Предпосылки:**
        - случайное возмущение $\varepsilon$  распределено нормально;
        - не подвержено гетероскедастичности;
        - модель не включает лаговые значения эндогенных переменных.
        При $DW \rightarrow 2$, автокорреляции нет.

        При $DW \rightarrow 0$, положительная автокорреляции.

        При $DW \rightarrow 4$, отрицательная автокорреляции.

        На практике проверка гипотезы **$H_0$**  об отсутствии автокорреляции остатков осуществляется с помощью сравнения статистики **DW** с теоретическими значениями **$d_l$** и **$d_u$** для заданного числа наблюдений n, числа независимых переменных модели k и уровня значимости α:

        - 0 < *DW* < *$d_l$* - гипотеза $H_0$  отвергается, есть положительная автокорреляция;
        - *dl* < *DW* < *$d_u$* - зона неопределённости;
        - $*d_u*$ < *DW* < **4 - $*d_u*$ - гипотеза $H_0$  не отвергается, автокорреляции нет;
        - 4 - $*d_u*$ < *DW* < **4 - $*d_l*$ - зона неопределённости;
        - 4 - $*d_l*$ < *DW* < **4 - гипотеза $H_0$ отвергается, есть отрицательная автокорреляция.

        **При использовании теста *DW* следует учитывать следующие ограничения:**

        - он применим лишь для модели с ненулевым свободным членом;
        - остатки должны описываться авторегрессионной моделью первого порядка;
        - регрессоры являются нестохастическими;
        - модель не подвержена гетероскедастичности;
        - применяется для выявления автокорреляции только между регрессионными остатками в последовательных наблюдениях.
    keywords: [Дарбина-Уотсона, Автокорреляция ]
num11:
    text: |-
    keywords: []
num12:
    text: |-
    keywords: []
num13:
    text: |-
    keywords: []
num14:
    text: |-
    keywords: []
num15:
    text: |-
    keywords: []
num16:
    text: |-
    keywords: []
num17:
    text: |-
    keywords: []
num18:
    text: |-
    keywords: []
num19:
    text: |-
    keywords: []
num20:
    text: |-
    keywords: []
num21:
    text: |-
    keywords: []
num22:
    text: |-
    keywords: []
num23:
    text: |-
    keywords: []
num24:
    text: |-
    keywords: []
num25:
    text: |-
    keywords: []
num26:
    text: |-
    keywords: []
num27:
    text: |-
    keywords: []
num28:
    text: |-
    keywords: []
num29:
    text: |-
    keywords: []
num30:
    text: |-
    keywords: []
num31:
    text: |-
        ### 31) Модели бинарного выбора. Недостатки линейной модели.
        Модели бинарного выбора полезны, если вы хотите оценить вероятность наступления некоторого события и определить, от чего эта вероятность зависит, или если вы хотите выяснить, какие факторы и каким образом влияют на решения, принимаемые индивидом.

        **1) Линейная модель вероятности.**

        В такой модели мы можем считать, что вероятность наступления события (например, возвращения кредита) линейно зависит от некоторого фактора  $x$ ****(например, от заработной платы индивида). Тогда такую модель называют линейной моделью вероятности и записывают следующим образом:

        $$
        p_i = P(y_i = 1) = \beta_1 + \beta_2x_i 
        $$

        На практике линейная модель вероятности используется сравнительно редко, так как обладает недостатками. Главный из них — сложности с интерпретацией результатов: в такой модели предсказанные значения вероятности могут быть отрицательными или превышать единицу, что заведомо не соответствует действительности.

        **2) Логит-модель.**
        В рамках логит-анализа для описания вероятности наступления события используется логистическая функция:
        $$
        F(z_i) = \frac{1}{1 + e^{-z_i}} 
        $$

        Если мы анализируем случай парной взаимосвязи (то есть случай, когда вероятность наступления события зависит от единственного фактора $x$), то логит-модель может быть записана так:

        $$
        P(y_i = 1) = F(z_i) = \frac{1}{1 + e^{-z_i}} 
        $$

        Где $z_i = b_1 + b_2x_i$.
        
        **3) Пробит-модель.**

        Альтернативным способом оценивать параметры модели бинарного выбора является пробит-модель.

        Её отличие от логит-модели состоит в том, что вместо логистической функции для описания вероятности наступления события используется функция стандартного нормального распределения.

        $$
        P(y_i = 1) = \Phi(z_i) = \Phi(\beta_1 + \beta_2x_i^{(2)} + ... + \beta_kx_i^{(k)})
        $$

        Здесь $\Phi(z_i)$ - функция стандартного нормального распределения.

        Оценивание, тестирование гипотез и интерпретация результатов в рамках пробит-анализа проводится полностью аналогично случаю логит-анализа с поправкой на использование функции стандартного нормального распределения вместо логистической функции.

        В рамках логит-анализа для описания вероятности наступления события используется логистическая функция:
        keywords: [Модели бинарного выбора, Модели бинарного, бинарного, бинарные модели, недостатки линейной]
num32:
    text: |-
        ### 32) Модели множественного выбора: модели с неупорядоченными альтернативными вариантами.

        Зависимая переменная не является упорядоченной. Предполагается существование случайной полезности, которая влияет на выбор альтернатив. Случайные полезности являются линейными функциями от наблюдаемых характеристик и имеют аддитивно-разделяемую структуру.
        **Полезность:**

        $$
        U_{ij} = \mu_{ij} + \varepsilon_{ij}
        $$

        $\mu_{ij}$ - неслучайная функция наблюдаемых неизвестных параметров;
        $\varepsilon_{ij}$  - ненаблюдаемый остаточный член. 

        $$
        P(y_i = j) = P(U_{ij} = max(U_{i1}, U_{i2}, \ldots, U_{iM} ))
        $$

        $$
        P(y_i = j) = \frac{exp(\mu_{ij})}{exp(\mu_{i1}) + exp(\mu_{i2})  + \ldots + exp(\mu_{iM})}
        $$

        Один из уровней полезности принимают равным нулю $(\mu_{i1}=0)$ и полагают, что $\mu_{ij}$ является линейной функцией от наблюдаемых переменных:

        $$
        \mu_{ij} = x'_{ij}\beta \\
        \\
        P(y_i = j) = \frac{exp(x'_{ij}\beta)}{1 + exp(x'_{i2}\beta) + \ldots + exp(x'_{iM}\beta)}
        $$

        Данное выражение представляет собой logit – модель с множественными альтернативами.
    keywords: [Модели множественного выбора, неупорядоченные альтернативы, модели с неупорядоченными альтернативными вариантами]
num33:
    text: |-
        ### 33) Модели множественного выбора: модели с упорядоченными альтернативными вариантами.

        Модели множественного выбора с упорядоченными альтернативами строятся на основе латентной переменной, которая линейно зависит от вектора объясняющих переменных:

        $$
        y^* = \beta x + \varepsilon
        $$

        Пусть случайные возмущения независимы и имеют стандартное нормальное распределение. Латентная переменная связана с наблюдаемой переменной *у* системой уравнений (пример для 3 классов):

        $$
        y =\begin{equation}
        \left\{ \begin{aligned} 
        &0, y^* \le 0 \\
        &1, 0 < y^* \le \mu_1 \\
        &2, \mu_1 < y^* \le \mu_2
        \end{aligned} \right.
        \end{equation}
        $$

        Уровни цензурирования (пороговые значения для эндогенной переменной) неизвестны и оцениваются вместе с параметрами. Заменим в неравенствах латентную переменную ее модельным представлением  и вычтем линейную форму хр из обеих частей каждого неравенства:

        $$
        y_i =\begin{equation}
        \left\{ \begin{aligned} 
        &0, \varepsilon \le -x_i\beta \\
        &1, -x_i\beta < \varepsilon \le \mu_1 - x_i\beta \\
        &2, \mu_1 - x_i\beta < \varepsilon \le \mu_2 - x_i\beta
        \end{aligned} \right.
        \end{equation}
        $$

        В зависимости от выбора модели, случайные возмущения имеют логистическое или нормальное распределение. Для пробит-модели вероятности значений случайной величины определяются следующим образом:
        
        $$P(y = 0) = \Phi(-x\beta) \\
        P(y = 1) = \Phi(\mu_1 -x\beta) - \Phi(-x\beta) \\
        P(y = 2) = \Phi(\mu_2 -x\beta) - \Phi(\mu_1 -x\beta)$$
    keywords: [Модели множественного выбора, упорядоченные альтернативы, модели с упорядоченными альтернативными вариантами]
num34:
    text: |-
        ### 34) Модели множественного выбора: гнездовые logit-модели.

        Гнездовые logit-модели (Nested logit models) являются одним из типов моделей множественного выбора, используемых для анализа данных о выборе потребителей. Эти модели обычно применяются в случаях, когда выбор нескольких альтернатив может быть сгруппирован или организован по определенным критериям.

        В гнездовой logit-модели предполагается, что наблюдаемые альтернативы делятся на группы (или "гнезда"), и каждая группа имеет свой набор связанных альтернатив. Потребитель выбирает между группами альтернатив, а затем внутри выбранной группы совершает конечный выбор.

        Формула гнездовой logit-модели может быть представлена следующим образом:

        $$
        P{ij} = \frac{e^{V{ij}/\lambda i}}{\sum k e^{V{ik}/\lambda i}}
        $$

        Где:
        $P_{ij}$  - вероятность выбора альтернативы j в гнезде i*;*

        $*V_{ij}$ -* "utility" альтернативы j в гнезде i, которая может быть определена как линейная комбинация объясняющих переменных и их коэффициентов: $V_{ij} = \beta_i X_{ij}$ ;

        $*\lambda_i$ -* параметр дисперсии, который характеризует степень корреляции между альтернативами внутри гнезда.
    keywords: [Модели множественного выбора, гнездовые logit-модели, гнездовые logit модели, гнездовые логит модели, гнездовые логит-модели, гнёздовые logit-модели, гнёздовые logit модели, гнёздовые логит модели, гнёздовые логит-модели]
num35:
    text: |-
        ### 35) Модели счетных данных (отрицательная биномиальная модель, hurdle-model).

        **Отрицательная биномиальная модель:**

        Пусть $X$ - дискретная случайная величина, представляющая количество неудач до достижения  $r$ -го успеха в серии испытаний с вероятностью успеха $p$. Тогда функция вероятности для нее задается формулой:

        $P(X=x) = \binom{x+r-1}{x} (1-p)^r p^x, \quad x=0,1,2,...$

        **Hurdle-модель:**

        Пусть $X$ - дискретная случайная величина, представляющая количество наблюдений, проходящих через барьер (hurdle) $h$, и имеющая распределение Пуассона с параметром $\lambda$ , а затем, если наблюдение прошло через барьер, количество событий имеет распределение с отрицательной биномиальной функцией вероятности. Тогда функция вероятности для модели задается формулой:

        $$
        P(X=x) = \begin{cases}
        (1-e^{-\lambda}) + e^{-\lambda} \cdot \binom{x+h-1}{x} (1-p)^h p^x, & \text{if } x > 0, \\
        (1-e^{-\lambda}), & \text{if } x=0.
        \end{cases}
        $$

        где $h$  - барьер, $\lambda$ - параметр для распределения Пуассона, $p$ - вероятность успеха в схеме с отрицательной биномиальной функцией вероятности.    
    keywords: [Модели счетных данных, отрицательная биномиальная модель, hurdle-model]
num36:
    text: |-
        ### 36) Модели усеченных выборок.

        Усеченная выборка - это выборка, из которой удалены определенные значения данных (обычно крайние значения), что позволяет избежать искажения статистических показателей. Существует несколько моделей усеченных выборок, одной из которых является усеченное нормальное распределение.

        Для усеченного нормального распределения математическое ожидание и дисперсия определяются следующим образом:

        **1) Математическое ожидание усеченной выборки:**

        $$
        \mu_t = \frac{\mu - \mu_c}{1 - c}
        $$

        Где:
        - $\mu$ - математическое ожидание исходного нормального распределения, 
        - $\mu_c$ - математическое ожидание усеченной выборки, 
        - $c$ - процент усечения (например, 5% усеченной выборки имеет ($c$  = 0.05).

        **2. Дисперсия усеченной выборки:** 

        $\sigma_t^2 = \frac{\sigma^2}{(1 - c)^2}$ 

        Где: 

        -  $\sigma$ - стандартное отклонение исходного нормального распределения, 

        - $\sigma_t$ - стандартное отклонение усеченной выборки.

        Другой популярной моделью усеченной выборки является усеченное **Лапласово распределение** (также известное как симметричное экспоненциальное распределение). В этой модели удаление происходит с равной вероятностью как слева, так и справа от выбранного центра.

        Формула для плотности вероятности усеченного Лапласового распределения выглядит следующим образом: $f(x) = \frac{1}{2b}e^{-\frac{\vert x - \mu \vert}{b}} \text{, где } x \geq \mu \text{ или } x \leq \mu$

        Где: 

        - $b$ - ширина усечения, 

        - $\mu$ - центр усечения.

        Эти модели могут быть применены в различных исследованиях, где необходимо избежать влияния экстремальных значений на статистический анализ.
    keywords: [Модели усеченных выборок, Модели усечённых выборок,  усеченные выборки]
num37:
    text: |-
        ### 37) Модели цензурированных выборок (tobit-модель)

        Существуют экономических задачи, в которых зависимая переменная может принимать
        значения из некоторого ограниченного сверху или снизу диапазона

        Тобит-модель — это одна из моделей, которая используется для анализа зависимости между ограниченной или цензурированной экзогенной ($y$) переменной и эндогенной переменной, которая принимает любые значения. 

        Правая тобит модель (ограничение сверху):

        $$
        y_i = \begin{cases}
        y_i^*, y_i<y_U \\
        y_U, y_i\ge y_U \\
        \end{cases}
        $$

        Левая тобит модель (ограничение снизу

        $$
        y_i = \begin{cases}
        y_i^*, y^*_i > y_L  \\
        y_L, y_i^* \le y_L
        \end{cases}
        $$

        Существует ситуация, когда наблюдения ограничены с обеих сторон: 

        $$
        y_i = \begin{cases}
        y_i^*, y_L < y_i^* < y_U \\ 
        y_L, y_i \le y_L \\
        y_U, y_i \ge 
        \end{cases}
        $$

        Например, при моделировании доходов накладывается ограничение: Никто не может зарабатывать меньше нуля.

        Перед использованием тобит модели надо:

        1. Определить пределы зависимой переменной 
        2. Оценить модель, используя метод макс. правдоподобия

        ---

        Модель Хекмана (или Тобит II) строится на основе двух различных уравнений: одно используется для отбора выборки, а второе для построения модели.

        Хекит-модель включает два уравнения:

        - Уравнение определения (бинарного выбора)

        $$
        y^*=x^Tb+\varepsilon
        $$

        - Уравнение результатов (линейная модель)

        $$
        g^*=z^Tc+u
        $$

        Тобит II модель имеет вид:

        $$
        g = \begin{cases}
        1, g^* > 0, \\
        0, g^* \le 0

        \end{cases} \\
        y = \begin{cases}
        y^*, g = 1, \\
        0, g=0
        \end{cases}
        $$
  
    keywords: [тобит, tobit, модели цензурированных выборок, модели цензурированных]
num38:
    text: |-
        ### 38) Модели случайно усеченных выборок (selection model)
        
        Усеченная регрессия или модель усеченных выборок — модель регрессии в условиях, когда выборка осуществляется только из тех наблюдений, которые удовлетворяют априорным ограничениям, которые обычно формулируются как ограничение снизу и/или сверху зависимой переменной.

        Урезание приводит к смещению МНК оценок, поэтому такие модели оцениваются по методу максимального правдоподобия.

        Пусть $y$ описывается уравнением: $y_i = X_i^T\beta+\varepsilon_i$, но в выборку попадают данные, для которых $y_{\text{min}} \le y_i \le  y_{\text{max}}$. В случае одностороннего усечения, второй порог равен бесконечности (+ или - соответственно)

        Функция правдоподобия для модели:
        $$l(\beta, \sigma)=\sum_{y_{\text{min}} \le y_i \le  y_{\text{max}}} \ln f(\frac{y_i-X_i^T\beta}{\sigma})-\ln[F(\frac{y_{\text{max}}-X_i^T\beta}{\sigma}) - F(\frac{y_{\text{min}}-X_i^T\beta}{\sigma})]$$
    keywords: [Модели случайно усеченных выборок, selection model]
num39:
    text: |-
        ### 39) Логит-модель. Этапы оценки. Области применения.

        Логит-модель, статистическая модель, применяемая для моделирования вероятности бинарных зависимых переменных на основе логарифма отношения шансов успеха к неудаче. 

        Логит модель объясняет бинарную (дискретную) переменную, $y_i\in \{0, 1\}$. В моделях предполагает, что существует некоторая $y^*_i$, которая и определяет:

        $$
        y_i = \begin{cases}1, y_i^*\ge0 \\ 0, y_i^* < 0\end{cases}
        $$

        Модель строится для $y_i^*=\beta_0+\beta_1x_i+...+\varepsilon_i$

        Для логит модели $\varepsilon_i \sim logistic$  — то есть логистическое распределение ($\Lambda(t)=\frac{e^{-t}}{(1+e^{-t})^2}$)

        ---

        Вероятность того, что $y_i$ принимает значение 1 можно выразить

        $$
        P(y_i=1)=P(y_i^*\ge0)=P(\beta_0+\beta_1x_1+...+\varepsilon_i\ge0)= \\
        P(-\varepsilon_i \le \beta_0+\beta_1x_1+...)=F(X^T_iB)
        $$

        Где $F(X_i^TB)$ — значение функции распределения в точке $X_i^TB$. Для логит модели $F(z)=\Lambda(t)$. Соответственно $P(y_i=0)=1-\Lambda(X_i^TB)$

        ---

        Этапы оценки логит-модели:

        1. Определение зависимой переменной и факторов
        2. Построение $Z$ -переменной как линейной комбинации независимых переменных
        3. Построение уравнения для искомой вероятности события и нахождения производных для оценки кумулятивного и предельного воздействия факторов
        4. Проведение вычислений по методу максимального правдоподобия
        5. Интерпретация результатов
        6. Качество оценивания

        ---

        **Примеры:**

        - Медицина: Успешность лечения, вероятность заболевания
        - Маркетинг: Склонность к покупке, вероятность отклика на предложение
        - Финансы: Скоринг в банках
        - Социальные науки: Успешность окончания школы, вероятность голосования, вероятность получения зачета
        - Компьютерное зрение: распознавание образов, классификация изображений, наличие объекта на фото
    keywords: []
num40:
    text: |-
        ### 40) Пробит-модель. Этапы оценки. Области применения.

        Пробит-модель — статистическая модель, используемая для моделирования вероятности бинарного результата на основе нормального распределения. Она основана на функции пробита, которая преобразует линейную комбинацию регрессоров в вероятность успеха.

        Модель бинарного выбора называется пробит-моделью, если удовлетворяет:

        1. Остатки бинарного выбора $\varepsilon_i \sim N(0, 1)$
        2. Функция распределения вероятностей распределена по нормальному закону

        Пробит-регрессия может быть представлена в виде:

        $$
        p = F(z)=\frac{1}{2\pi}\int^z_{-\infty}e^{-\frac{u^2}{2}}du
        $$

        $p$ — вероятность успеха, $z$— линейная комбинация предикторов.

        Линейная комбинация $z$ выражается:

        $$
        z_i=\beta_0+\beta_1x_1+...
        $$

        При построении модели нужно минимально 10 исходов на каждую независимую переменную, а рекоммендовано (30-50). То есть если 50/100 пациентов выздоравливают, то максимальное число независимых переменных $50/10=5$

        ---

        Для оценки параметров используют метод максимального правдоподобия

        Лог. функция правдоподобия:

        $$
        \log L=\sum^n_{i=1}y_i \log F(X_i^T\beta)+\sum_{i=1}^n(1-y_i)\log(1-F(X_i^T\beta))
        $$

        ---

        **Примеры:**

        - Медицина: Успешность лечения, вероятность заболевания
        - Маркетинг: Склонность к покупке, вероятность отклика на предложение
        - Финансы: Скоринг в банках
        - Социальные науки: Успешность окончания школы, вероятность голосования, вероятность получения зачета
        - Компьютерное зрение: распознавание образов, классификация изображений, наличие объекта на фото
    keywords: [пробит-модель, probit-model, probit, пробит, пробит модель]
num41:
    text: |-
        ### 41) Метод максимального правдоподобия.
        Метод максимального правдоподобия ****— это метод оценивания неизвестного параметра путём максимизации функции правдоподобия. Метод основан на предположении о том, что вся информация о выборе содержится в функции правдоподобия.

        Большинство статистических показателей для оценки бинарного выбора рассчитываются через логарифм функции правдоподобия.

        Для того, чтобы оценить параметр, требуется максимизировать функцию правдоподобия. Функция максимального правдоподобия для независимой выборки:

         

        $$
        f_X(x | \theta) = \prod f_{X_i}(x_i | \theta)
        $$

        Для удобства вычислений производной берется логарифмированная функция правдоподобия (log likelihood function)

        $$
        L(x| \theta)=\sum \ln f_{X_i}(x_i | \theta)
        $$

        Далее берется производная по параметру $\theta$ и находится максимум. Найденный параметр и есть оценка.
    keywords: [метод максимального правдоподобия, likelyhood]
num42:
    text: |-
        ### 42) Свойства оценок метода максимального правдоподобия

        Если функция $f(x)$ распределения случайных величин (зависищая от параметров $\theta)$ удовлетворяет некоторым условиям регулярности, то оценки методом правдоподобия $\hat{\theta}$ обладают следующими свойствами:

        1. Инвариативность: Если $\hat{\theta}$ — оценка МП для $\theta$ и непрерывной функции $g(\theta)$, то $g(\hat{\theta})$ является оценкой МП для $g(\theta)$
        2. Состоятельность для $\theta$
        3. Асимптотическая нормальность и эффективность: ${\sqrt {n}}({\hat {\theta }}-\theta )\rightarrow N(0,F^{-1}(\theta))$. Здесь $F(\theta)=\lim_{n \rightarrow \infty} \frac{1}{n} F_n(\theta)$, где $F_n(\theta)$ — асимптотическая информационная матрица Фишера.
    keywords: [свойства оценок, свойства оценок метода максимального правдоподобия]
num43:
    text: |-
        ### 43) Информационная матрица и оценки стандартных ошибок для оценок параметров logit и probit моделей. Интерпретация коэффициентов в моделях бинарного выбора.

        Для оценки свойств оценок метода макс. правдоподобия используется информационная матрица:

        $$
        I(\theta)=E[g(\theta)g(\theta)^T]
        $$

        Здесь $g(\theta)$ — градиент функции правдоподобия

        В оптимальной точке информационная матрица совпадает с минус мат. ожиданием Гессиана:

        $$
        I=-E(H_0)
        $$

        ---

        Оценки максимального правдоподобия могут быть смещенными, но являются состоятельными и асимптотически нормальными, что означает:

        $$
        \sqrt{n}(\hat{\theta}-\theta)\rightarrow^dN(0, I_\infty^{-1})
        $$

        Здесь $I_\infty=-\lim_{n\rightarrow\infty}{\frac{1}{n}E(H)}$ — асимптотическая информационная матрица 

        ---

        Интерпретация коэффициентов моделей logit и probit отличается от интерпретации коэфов обычной линейной модели. 

        LR-статистика является аналогом статистики Фишера и проверяет гипотезу о незначимости всех факторов модели:

        $$
        LR=-2(RestLog(L)-log(L))
        $$

        Здесь $log(L)$ — логарифм функции правдоподобия, $RestLog(L)$  — остаток логарифма функции правдоподобия. 

        Статистика имеет распределение $\chi^2(k-1)$, $k$ — число факторов регрессии

        ---

        Коэффициент детерминации Макфаддена $(McFadden's \ R^2)$ в моделях бинарного выбора представляет собой меру качества модели.

        Чем ближе значение к 1, тем лучше модель. Если значение коэффициента равно 0, это означает, что модель никак не объясняет данные.

        $$
        McFadden\ R^2=1 - \frac{log(L)}{RestLog(L)}
        $$

        $RestLog(L)$ — остаток логарифма правдоподобия
    keywords: [информационная матрица, оценка стандартных ошибок, матрица фишера, оценка параметров logit, оценка параметров probit]
num44:
    text: |-
        ### 44) Мера качества аппроксимации и качества прогноза logit и probit моделей

        Для моделей бинарного выбора трудно предложить естественную меру качества аппроксимации на подобии $R^2$  для линейной модели. Меры сравнения зачастую строятся путем прямого или косвенного сравнения текущей и тривиальной модели.

        По аналогии с коэффициентом детерминации введем псевдо коэффициент детерминации

        $$
        R^2_{\text{pseudo}}=1 - \frac{1}{1 + \frac{2(\ln L - \ln L_0)}{n}}
        $$

        Альтернативой называется индексом отношения правдоподобия Макфаддена

        $$
        R^2_{\text{McFadden}}=1 - \frac{\ln L}{\ln L_0}
        $$

        Где $L$ — логарифм правдоподобия текущей модели, $L_0$  — логарифм правдоподобия включащей лишь свободный член (тривиальной модели). Тогда чем больше разность между величинами, тем лучше полная модель по сравнению с усеченной

        ---

        Альтернативный подход состоит в вычислении прогноза по сравнению с фактическим значением. 

        Если вероятность предсказания больше 0.5, то прогноз = 1, иначе 0. Так как логистическое и нормальное распределение симметрично относительно нуля:

        $$
        \begin{cases}\hat{y}_i=1, X_i^T\beta >0 \\
        \hat{y}_i=0, X_i^T\beta < 0 \\
        \end{cases}
        $$

        Тогда доля неправильных прогнозов:

        $$
        wr_1 = \frac{1}{n}\sum^n_{i=1}(y_i-\hat{y}_i)^2
        $$

        Здесь мы также будем сравнивать ошибку прогноза у текущей и тривиальной модели. У последней все предсказанные вероятности будут равны доле успехов в выборке: $p=\frac{n_1}{n}$. Тогда прогноз будет одинаковый для всех наблюдений. 

        $$
        \begin{cases}wr_1=1-\hat{p}, \hat{p}>0.5 \\
        wr_0=\hat{p}, \hat{p} \le 0.5
        \end{cases}
        $$

        Тогда качество подгонки может быть оценено как $R^2_p=1-\frac{wr_1}{wr_0}$.
    keywords: [Мера качества аппроксимации, мера качества прогноза logit, качество прогноза logit, logit и probit, логит и пробит]
num45:
    text: |-
        ### 45) Временные ряды: определение, классификация, цель и задача моделирования временного ряда.

        Под **временным рядом** (динамическим рядом, или рядом динамики) подразумевается
        совокупность наблюдений некоторого признака Y за ряд последовательных моментов времени.

        При рассмотрении модели регрессии характер экспериментальных данных обычно не так важен. Однако во временных рядах наблюдения нельзя считать независимыми, так как отбор производится строго в определенной последовательности.

        Отдельные наблюдения называют уровнями временного ряда $(y_t, t = 1, 2, ..., n)$, $n$ — число уровней или длина временного ряда

        Компоненты временного ряда: 

        - $T$ — тренд, плавно меняющаяся компонента. Описывает чистое влияние долговременных факторов.
        - $S$ — сезон. Отражает повторяемость экономических процессов в течении не очень длительного периода
        - $C(t)$ — циклическая компонента, колебания с периодом несколько лет
        - $\varepsilon$ — остаточная (случайная) компонента. Отражает влияние, не поддающееся учету.

        ---

        **Целью исследования временного ряда** является определение закономерностей в изменении уровней ряда и построение модели изменения с целью дальнейшего прогнозирования

        **Задачи** моделирования временного ряда:

        - Разложение наблюдаемых изменений на две составляющие: детерминированную и случайную
        - Прогнозирование развития изучаемого процесса исходя из того, что установленная тенденция может быть экстраполирована на будущий период
        - Моделирование сезонных колебаний

        ---

        Тренд-модели сезонных колебаний: 

        - Аддитивная

        $$
        y_t=f_t+S_t+\varepsilon_t
        $$

        - Мультипликативная

        $$
        y_t=f_t\cdot S_t\cdot \varepsilon_t
        $$

        - Смешанная
        $$y_t=f_t\cdot S_t + \varepsilon_t$$
    keywords: [Временные ряды определение, временные ряды классификация, цель и задача моделирования временного ряда]
num46:
    text: |-
        ### 46) Исследование структуры одномерного временного ряда.

        В общем случае временной ряд представляет собой функцию четырех компонент:

        $$
        f(t), S(t), C(t), \varepsilon(t)
        $$

        *f*(*t*) – тренд или тенденция (наиболее важная) - это устойчивая закономерность, наблюдаемая в течение длительного периода времени.  

        *S*(*t*) – сезонная (периодическая) компонента связана с наличием факторов, действующих с заранее известной периодичностью.

        *C*(*t*) –циклическая компонента, колебания с периодом несколько лет - неслучайная функция, описывающая длительные периоды (много лет) относительного подъема и спада в зависимости от фазы экономического цикла в данный исторический момент.

        ε(*t*) – остаточная компонента - часть временного ряда, оставшаяся после выделения систематических компонент.  Она:

        - Отражает воздействие многочисленных факторов случайного характера, не учитываемых при оценке тренда, и представляет собой случайную, нерегулярную компоненту.
        - Является обязательной составной частью любого временного ряда в экономике, так как случайные отклонения неизбежно сопут­ствуют любому экономическому и социальному процессу.

        Структура любого временного ряда определяется тем, насколько тесно взаимосвязаны меду собой текущие наблюдения $y_t$ и предыдущие $y_{t-1}$. Для исследования структуры используют автокорреляционную функцию (АКФ).

        АКФ - это последовательность коэффициентов автокорреляции различного порядка.

        АКФ измеряется с помощью линейного коэффициента корреляции между уровнями $$ $y_t$ и уровнями этого же временного ряда, сдвинутыми на несколько  $\tau$ шагов

        $\tau$ - временной лаг

        Формула для расчета коэффициентов автокорреляции порядка $\tau$: 

        $$
        r_{y_t y_{t-1}}=\dfrac {\overline{(y_t y_{t-1})}-\bar{y_t}\bar{y_{t-1}}}{\sigma_{y_t}\sigma_{y_{t-1}}}
        $$

        Длина АКФ $\approx \frac n4$

        Если наибольшим окажется коэффициент первого или второго порядка, то ряд динамики имеет ярко-выраженную тенденцию. Если наибольший - порядка k, то ряд содержит периодичность с k моментом времени (циклическую компоненту). Если ни один коэффициент не значим - ряд имеет случайный характер или сильную нелинейную тенденцию (нужно провести дополнительный анализ).
    keywords: [Исследование структуры одномерного временного ряда]
num47:
    text: |-
        ###  Функциональные зависимости временного ряда. Предварительный анализ временных рядов.
        
        Чаще всего на практике приходится иметь дело с рядами, включающими три компоненты – тренд, сезонную и случайную составляющие. Такие процессы принято называть тренд-сезонными.

        В зависимости от вида связи между компонентами могут быть построены следующие модели:

        - Аддитивная

        $$
        y_t = f_t + S_t + \varepsilon_t
        $$

        - Мультипликативная

        $$
        y_t = f_t \cdot S_t \cdot \varepsilon_t
        $$

        - Смешанная

        $$
        y_t = f_t \cdot S_t + \varepsilon_t
        $$

        В ходе предварительного анализа динамика исследуемого процесса представляется в графическом формате. При графическом отобра­жении динамики по оси абсцисс откладываются значения переменной *t*, а по оси ординат - соответствующие значения показателя *Y(t)*.

        К процедурам предварительного анализа относятся:

        - выявление аномальных наблюдений;
        - проверка наличия тренда;
        - сглаживание временных рядов
    keywords: [Функциональные зависимости временного ряда]
num48:
    text: |-
        ### 48) Процедура выявления аномальных наблюдений. Причины аномальных значений. Блочные диаграммы по типу «ящика с усами».
        
        В связи с тем, что наличие аномальных наблюдений приводит к искажению результатов моделирования, необходимо убедиться в отсутствии аномальных наблюдений. Поэтому процедура выявления аномальных наблюдений является обязательной процедурой этапа предварительного анализа данных.

        Аномальные значения - это значения, которые сильно отличаются от общей модели исследуемого процесса. Существует несколько причин возникновения аномальных наблюдений. Среди них:

        - Значения, отражающие объективное развитие процесса, но сильно отличающиеся от общей тенденции, так как проявляют свои экстремальные воздействия крайне редко.
        - Значения, возникающие вследствие изменений методики расчета. (Эти значения не должны исключаться из рассмотрения, а приниматься за новую точку отсчета, начиная с которой предыдущие значения временного ряда должны быть пересчитаны по новой методике.)
        - Значения, возникающие вследствие ошибок при измерении показателя, а также значения, связанные с различными катастрофическими явлениями, не влияющими на дальнейший ход развития явления. (Эти значения должны быть исключены из рассмотрения, так как они искажают представление о характере развития явления и могут оказать существенное влияние на выводы.)

        Для выявления аномальных значений существуют несколько методов: процедура выявления аномальных наблюдений на основе распределения Стьюдента, на основе метода Ирвина , а так же ящики с усами. Подробнее пр оя щик с усами: Это инструмент визуализации данных, который состоит из ящика (позволяет определить медианное значение данных, нижний квартиль, верхний квартиль), усов (используются для обозначения степени разброса (дисперсии) за пределами верхнего и нижнего квартилей) и единичных точек данных за пределами усов, которые считаются выбросами
        
        ![картинка](https://prod-files-secure.s3.us-west-2.amazonaws.com/ea82dced-4bb1-4744-bb7f-f725865d7e52/7016a4a3-3f89-40ee-b63f-74c2a06db084/2024-06-10_15_59_48-%D0%94%D0%B8%D0%B0%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B0_%D1%80%D0%B0%D0%B7%D0%BC%D0%B0%D1%85%D0%B0_(_%D1%8F%D1%89%D0%B8%D0%BA_%D1%81_%D1%83%D1%81%D0%B0%D0%BC%D0%B8_).png)

        На питоне: sns.boxplot()
    keywords: [ящик с усами, аномальные наблюдения, процедура выявления аномальных наблюдений]
num49:
    text: |-
        ### 49) Процедура выявления аномальных наблюдений на основе распределения Стьюдента. Особенности применения метода. Анализ аномальных наблюдений.

        По имеющейся выборке вычисляется статистика:

        $$
        \hat{\tau} = \dfrac{|y^*-\bar{y}|}{S_y}
        $$

        где $𝑦^* = 𝐴𝑟𝑔 max|𝑦_𝑖−\bar{𝑦}|$ – наблюдение, предположительно являющееся аномальным; 

        $\bar{y}, 𝑆_𝑦$ – среднее и среднеквадратическое отклонение соответственно.

        ```python
        data1['tau']=abs(data1['Close']-np.mean(data['Close']))/np.std(data['Close'])
        ```

        Величина 𝜏 называется максимальным относительным отклонением. Далее проводится сравнение 𝜏 с критическими значениями

        $$
        \tau_{\alpha,n} = \dfrac{t_{кр}(1-\frac{\alpha}{2},n-2)\sqrt{n-1}}{\sqrt{n-2+t_{кр}^2(1-\frac{\alpha}{2},n-2)}}
        $$

        ```python
        tau_cr=(stats.t.ppf(1-0.05/2,len(data)-2)*(len(data)-1)**0.5)/(len(data)-2+(stats.t.ppf(1-0.05/2,len(data)-2))**2)**0.5

        tau_cr2=(stats.t.ppf(1-0.001/2,len(data)-2)*(len(data)-1)**0.5)/(len(data)-2+(stats.t.ppf(1-0.001/2,len(data)-2))**2)**0.5
        ```

        где $𝑡_{кр} (1−\frac{𝛼}2,𝑛−2)$ – критическое значение распределения Стьюдента при различных значениях уровня значимости α и количеством степеней свободы 𝑛−2.

        Максимальные относительные отклонения в процессе вычисления разделяют на три группы в соответствии с условиями:

        1. $\hat{\tau}\le \tau_{0.05,n}$ наблюдение нельзя считать аномальным
        2. $\tau_{0.05,n} < \hat{\tau}\le \tau_{0.001,n}$  наблюдение может быть признано аномальным, если в пользу этого имеются и другие доводы.
        3. $\hat{\tau}> \tau_{0.001,n}$ наблюдение признается аномальным
    keywords: [выявление аномальных наблюдений, распределение Стьюдента, Стьюдента, аномалии Стьюдента, анализ аномальных наблюдений]
num50:
    text: |-
        ### 50) Процедура выявления аномальных наблюдений на основе метода Ирвина. Особенности применения метода. Анализ аномальных наблюдений.
        Для всех или только для подозреваемых в аномальности наблюдений вычисляется величина  $𝜆_𝑡$:

        $$
        \lambda_t = \dfrac{|y_t-y_{t-1}|}{S_y}
        $$

        где                        
        - $S_y = \sqrt{\dfrac{\sum_{t=1}^n (y_t-\bar{y})^2}{n-1}}$
        - $\bar{y}=\frac 1n \sum_{t=1}^n y_t$

        Если рассчитанная величина $𝜆_𝑡$ превышает табличный уровень, то уровень $𝑦_𝑡$  считается аномальным. Аномальные наблюдения необходимо исключить из временного ряда и заменить их расчетными значениями (средней арифметической двух соседних уровней ряда, либо заменой значением соответствующей трендовой кривой).

        Трендовые модели используются для моделирования динамических процессов, структура которых включает две составляющие: детерминированную, которую возможно описать с помощью гладкой аналитической функции, и случайную компоненты. Оценки будущих состояний ряда можно получить, используя метод экстраполяции
    keywords: [Процедура выявления аномальных наблюдений на основе метода Ирвина, метод Ирвина, особенности применения метода Ирвина, анализ аномальных наблюдений]
num51:
    text: |-
        ### 51) Проверка наличия тренда. Критерий серий, основанный на медиане. Особенности применения метода.

        Этапы критерия серий:

        1. Определяется медиана ряда (в экселе МЕДИАНА):

                                               $Me=\begin{cases} y_{m+1}, n=2m+1 &\text{- нечетное} \\ \dfrac{(y_m+y_{m+1})}2, n=2m &\text{- четное} \end{cases}$

        1. Образуется последовательность $𝛿_𝑖$  из плюсов и минусов:

        $$
        \delta_i=\begin{cases} +,&\text{если } y_t>Me, t=1,...,n \\ -,&\text{если } y_t<Me, t=1,...,n   \end{cases}
        $$

        Если значение 𝑦_𝑡  равно медиане, то это значение пропускается.

        1. Подсчитывается: **$v(n)$ - число серий в совокупности δ_i,** где под серией понимается последовательность подряд идущих плюсов или минусов. Один плюс или один минус тоже будет считаться серией; **$τ_{max} (n)$ - протяженность самой длинной серии.**
        2. Проверка гипотезы: при условии случайности ряда (при отсутствии систематической составляющей) протяженность самой длинной серии не должна быть слишком большой, а общее число серий - слишком маленьким.
        Чтобы не была отвергнута гипотеза о случайности исходного ряда (об отсутствии систематической составляющей), должны выполняться следующие неравенства (для 5% уровня значимости квантиль нормального распределения равен  $𝛼_{кр}$=1,96):

        Короче, считаем статистику ниже и смотрим, если оба неравенства выполняются - тренда нет, если хотя бы одно из них или сразу оба нарушаются - тренд есть    
        $$\begin{cases} \tau_{max}(n)<3.3(lg(n)+1) \\ v(n)> \frac12 (n+1-1.96\sqrt{n-1}           \end{cases}$$
    keywords: [Проверка наличия тренда, критерий серий основанный на медиане, особенности применения метода]
num52:
    text: |-
        ### 52) Проверка наличия тренда. Метод проверки разности средних уровней. Особенности применения метода.

        1. Исходный временной ряд **$у_1, у_2, у_3,...,у_n$** разбивается на две примерно равные по числу уровней части: в первой части  **$n_1$** первых уровней исходного ряда, во второй - **$n_2$**остальных уровней (**$n_1+n_2=n$)**   
        2. Для каждой из этих частей вычисляются средние значения и дисперсии (эксель СРЗНАЧ, СТАНДОТКЛОН.В):

        $\bar{y_1}=\dfrac{\sum_{t=1}^{n_1}y_t}{n_1}$    $\sigma_1^2=\dfrac{\sum_{t=1}^{n_1}(y_t-\bar{y_1})^2}{n_1-1}$    $\bar{y_2}=\dfrac{\sum_{t=n_1+1}^{n}y_t}{n_2}$   $\sigma_2^2=\dfrac{\sum_{t=n_1+1}^{n}(y_t-\bar{y_2})^2}{n_2-1}$

        1. Проверка равенства (однородности) дисперсий обеих частей ряда с помощью F-критерия Фишера, которая основана на сравнении расчетного значения этого критерия:

        $$
        F=\begin{cases} \dfrac{\sigma_1^2}{\sigma_2^2} &\text{если }\sigma_1^2>\sigma_2^2 \\ \dfrac{\sigma_2^2}{\sigma_1^2} &\text{если }\sigma_1^2<\sigma_2^2 \end{cases}
        $$

        с табличным (критическим) значением критерия Фишера (эксель **F.ОБР.ПХ)** $F_{кр}(\alpha,n_1-1,n_2-1)$

        с заданным ***уровнем значимости*** (уровнем ошибки) α.

        Если расчетное значение F меньше табличного F_кр  ***,*** то гипотеза о равенстве дисперсий принимается и переходят к четвертому этапу. Если  F  больше или равно F_кр  ***,*** гипотеза о равенстве дисперсий отклоняется и делается вывод, что данный метод для определения наличия тренда ответа не дает.

        1. Проверяется гипотеза об отсутствии тренда с использованием ***t*-критерия Стьюдента**. Для этого определяется расчетное значение критерия Стьюдента по формуле

        $$
        t=\dfrac{|\bar{y_1}-\bar{y_2}|}{\sqrt{\dfrac{(n_1-1)\sigma_1^2+(n_2-1)\sigma_2^2}{n_1+n_2-2}}\sqrt{\frac 1{n_1}+\frac 1{n_2}}}
        $$

        Если $t_{расч}<t_{кр}$ - гипотеза принимается, т.е. тренда нет, в противном случае тренд есть.   

        Заметим, что в данном случае табличное значение $t_{кр}$  берется для числа степеней свободы, равного $n_1+n_2-2$***,*** при этом данный метод применим только для рядов с монотонной тенденцией
    keywords: [Проверка наличия тренда, Метод проверки разности средних уровней, Особенности применения метода.]
num53:
    text: |-
        ### 53) Проверка наличия тренда. Метод Фостера-Стьюарта. Особенности применения метода.

        Этот метод дает более надежные результаты по сравнению с предыдущим (методом проверки разности средних уровней). Кроме самого тренда он позволяет установить наличие тренда дисперсии. При отсутствии тренда дисперсии разброс уровней ряда постоянен, при наличии тренда дисперсии дисперсия увеличивается или уменьшается.

        Определим две последовательности:

        $$
        k_t = \begin{cases} 1, &\text{если yt больше всех предыдущих уровней} \\ 0, &\text{в противном случаее}   \end{cases}, t=1,...,n
        $$

        $$
        l_t = \begin{cases} 1, &\text{если yt меньше всех предыдущих уровней} \\ 0, &\text{в противном случаее}   \end{cases}, t=1,...,n
        $$

        Вычислим величины 𝑠 и 𝑑, характеризующие изменение временного ряда и дисперсии:

                                            $s=\sum_{t=2}^n(k_t+l_t)$      $d=\sum_{t=2}^n(k_t-l_t)$

        Величина **s** характеризует изменение временного ряда, она может принимать значение от 0 (когда все уровни ряда равны) до n – 1 (ряд монотонный).

        Величина **d** характеризует изменение дисперсии временного ряда и изменяется от (– (n – 1)) (когда ряд монотонно убывает) до (n – 1) (когда ряд монотонно возрастает).

        Эти величины являются случайными с математическим ожиданием **µ** для значения **s** и **0** для значения **d**.

        Проверим гипотезы о случайности отклонения величины 𝑠 от ее математического ожидания µ и о случайности отклонения величины 𝑑 от нуля с помощью критерия Стьюдента для средней и для дисперсии:

        $t_s=\dfrac{|s-\mu|}{\sigma_1}$      $\sigma_1=\sqrt{2ln(n)-3.4253}$       $t_d=\dfrac{|d-0|}{\sigma_2}$       $\sigma_2=\sqrt{2ln(n)-0.8456}$

        $$
        \mu = \dfrac{1.693872 ln(n)-0.299015}{1-0.035092 ln(n)+0.002705 ln^2(n)}
        $$

        где µ – математическое ожидание величины 𝑠 для случайного временного ряда;
        $𝜎_1$ – среднеквадратичное отклонение 𝑠 для случайного временного ряда;
        $𝜎_2$ – среднеквадратичное отклонение 𝑑 для случайного временного ряда.

        ***Если*** **$t_кр$** ***больше*** ***расчетного*** ***значения*** **$t_кр>t_s, t_кр>t_d$*, то*** ***соответствующий*** ***тренд*** ***отсутствует.***

        Например,  если $t_s> t_кр$, а $t_d< t_кр$, то тренд ряда есть, а тренда дисперсии нет.    
    keywords: [Проверка наличия тренда, Метод Фостера-Стьюарта, Особенности применения метода]
num54:
    text: |-
        ### 54) Сглаживание временных рядов. Простая (среднеарифметическая) скользящая средняя. Взвешенная (средневзвешенная) скользящая средняя. Среднехронологическая. Экспоненциальное сглаживание

        Очень часто уровни экономического ряда динамики колеблются, так что тенденция развития экономического процесса скрыта случайными отклонениями.

        Сглаживание временного ряда позволяет отфильтровать мелкие случайные колебания и выявить основную тенденцию изменения исследуемой величины.

        При механическом сглаживании выравнивание отдельных уровней производится с использованием значений соседних уровней.

        Для сглаживания используются следующие методы:

        - Среднеарифметическая скользящая средняя

                                                          $\tilde{y_t}=\dfrac{\sum_{i=t-p}^{t+p}y_i}{2p+1}$,     $p<t<n-p$

        Сглаженное значение $\tilde{𝑦_𝑡}$ является среднеарифметическим из 2𝑝+1 соседних точек.    Наиболее часто используется сглаживание по 5 точкам:

        $$
        \tilde{y_t}=\dfrac{y_{t-2}+y_{t-1}+y_t+y_{t+1}+y_{t+2}}{5}
        $$

        - Взвешенная скользящая средняя

                                                          $\tilde{y_t}=\dfrac{\sum_{i=t-p}^{t+p}\rho_i y_i}{\sum_{i=t-p}^{t+p}\rho_i}$,     $p<t<n-p$

        В этом методе каждая из точек входит в общую сумму с весовым коэффициентом 𝜌_𝑖

        Например, для сглаживания по 5 точкам используют весовые коэффициенты (–3, 12, 17, 12, –3). Для сглаживания по 7 точкам используются коэффициенты (–2, 3, 6, 7, 6, 3, –2) или (5, –30, 75, 131, 75, –30, 5).

        - Среднехронологическая

                                     $\tilde{y_t}=\dfrac{\dfrac{y_{t-T/2}}{2}+\sum_{i=t-p}^{t+p}y_i+\dfrac{y_{t+T/2}}{2}}{T}$,     $\frac T2<t<n-\frac T2$

        Эта формула используется для моментных временных рядов. Обычно период сглаживания принимают равным году, т.е. Т=4 квартала или Т=12 месяцев.

        - Экспоненциальное сглаживание

        Используются все предшествующие точки, причем значения весовых коэффициентов убывают по экспоненте по мере удаления от текущей точки.  Текущая точка зависит от всех предыдущих точек:

        $$
        \tilde{y_t}=\dfrac{\sum_{i=1}^{t}\rho_iy_i}{\sum_{i=1}^{t}\rho_i}
        $$

        В таком виде она неудобна для использования, поскольку для каждой точки необходим свой набор весовых коэффициентов. Используя рекуррентные соотношения, получим выражение для текущей сглаженной точки как функцию от текущей несглаженной точки и предыдущей сглаженной:

                                                          $\tilde{y_t}=\alpha y_t+(1-\alpha)\tilde{y_{t-1}}$,      $0<\alpha<1$

        где 𝛼 – параметр сглаживания; (1− 𝛼) – коэффициент дисконтирования.

        Фиктивное начальное значение сглаженного ряда принимают равным первой точке или среднеарифметическому первых трех точек:

                                                             $\tilde{y_0}=y_1$    или     $\tilde{y_0}=\dfrac{y_1+y_2+y_3} 3$

        При сглаживании временного ряда по 2𝑝+1 соседним точкам р в начале и в конце ряда остаются несглаженными.

        Эти точки следует либо исключить из рассмотрения, либо использовать для них специальные формулы сглаживания для крайних точек.

        В частности, для сглаживания по трем точкам можно использовать формулы:

                                               $\tilde{y_1}=\dfrac{5y_1+2y_2-y_3}6$;       $\tilde{y_n}=\dfrac{5y_n+2y_{n-1}-y_{n-2}}6$

        Заметим, что при экспоненциальном сглаживании не теряются ни начальные, ни конечные точки.    
    keywords: [Сглаживание временных рядов, простая скользящая средняя, среднеарифметическая средняя, взвешенная (средневзвешенная) скользящая средняя, Среднехронологическая, Экспоненциальное сглаживание]
num55:
    text: |-
        ### 55) Трендовые модели. Без предела роста. Примеры функций. Содержательная интерпретация параметров.

        **Кривая роста** - плавная кривая, аппроксимирующая временной ряд.

        Аналитические методы выделения детерминированной компоненты временного ряда с помощью кривых роста реализуются в рамках моделей регрессии, в которых в роли зависимой переменной выступает $y_t$  , а в роли единственной объясняющей переменной время  $t$.

        **Без предела роста**. Функции, используемые для описания процессов с монотонным характером тенденции развития и отсутствием пределов роста. Эти условия справедливы для многих экономических показателей, например, для большинства натуральных показателей промышленного производства.

        **ПРИМЕР:** 

        1. прямая: $y_t = a_0 + a_1t$
        2. парабола: $y_t + a_0 + a_1t + a_2t^2$
        3. экспонента: $y_t = exp( a_0 + a_1t )$

        Параметр $а_0$ - начальное условие развития, $а_1$ - скорость развития, $а_2$ - изменение скорости развития. Полиномы высшей степени не используют, поскольку будут отражать случайные отклонения.
    keywords: [Трендовые модели без предела роста, Содержательная интерпретация параметров]
num56:
    text: |-
        ### 56) Трендовые модели. С пределом роста без точки перегиба. Примеры функций. Содержательная интерпретация параметров.

        Трендовые модели используются для моделирования динамических процессов, структура которых включает две составляющие: детерминированную, которую возможно описать с помощью гладкой аналитической функции, и случайную компоненты. Оценки будущих состояний ряда можно получить, используя метод экстраполяции.

        **Кривая роста** - плавная кривая, аппроксимирующая временной ряд.

        Аналитические методы выделения детерминированной компоненты временного ряда с помощью кривых роста реализуются в рамках моделей регрессии, в которых в роли зависимой переменной выступает $y_t$  , а в роли единственной объясняющей переменной время  $t$.

        **С пределом роста без точки перегиба**. Примерами показателей, для которых могут быть указаны пределы роста, являются среднедушевое потребление определенных продуктов питания, расход удобрений на единицу площади.

        **ПРИМЕР:**

        1. Модифицированная экспонента: $f(t) = k + ab^t$, где а < 0, 0 < b < 1, k - известная асимптота
        2. Логарифмическая пaрабола: $f(t) = a_0 * a_1^t * a_2^{t^2}$. 
        3. Логарифмировав получаем $ln(y_t) = ln(a_0) + t * ln(a_1) + t^2 * ln(a_2)$
    keywords: [трендовые модели, С пределом роста без точки перегиба, содержательная интерпретация параметров.]
num57:
    text: |-
        ### 57) Трендовые модели. С пределом роста и точкой перегиба или кривые насыщения. Примеры функций. Содержательная интерпретация параметров.

        Трендовые модели используются для моделирования динамических процессов, структура которых включает две составляющие: детерминированную, которую возможно описать с помощью гладкой аналитической функции, и случайную компоненты. Оценки будущих состояний ряда можно получить, используя метод экстраполяции.

        **Кривая роста** - плавная кривая, аппроксимирующая временной ряд.

        Аналитические методы выделения детерминированной компоненты временного ряда с помощью кривых роста реализуются в рамках моделей регрессии, в которых в роли зависимой переменной выступает $y_t$  , а в роли единственной объясняющей переменной время  $t$.

        **С пределом роста и точкой перегиба или кривые насыщения.** Эти кривые описывают как бы два последовательных лавинообразных процесса (когда прирост зависит от уже достигнутого уровня): один с ускорением развития, другой - с замедлением. S - образные кривые находят применение в демографических исследованиях, страховых расчетах и тд.

        **ПРИМЕР:**

        1. Кривая Гомпертца: $f(t) = k * a^{b^t}$. Если а > 1, асимптота, равная к, лежит ниже кривой, а сама кривая неизменно монотонна. Если b < 1 - монотонно убывает. Если b > 1 - монотонно возрастает. В данной кривой выделяют четыре участка: на первом- прирост функции незначителен, на втором - прирост увеличивается, на третьем - прирост константа, на четвертом - замедление темпов роста. Применив дважды логарифмирование получается линейная функция: $LN ln(ln f(t) - ln(k)) - LN ln(a) + t * ln(b)$
        2. Кривая Перля-Рида: Уравнение логистической кривой получается путем замены в модифицированной экспоненте $f(t)$ обратной величиной $\frac{1}{f(t)}$.   Тогда получаем     $f(t) = \frac{k}{1 + 10^{a - bt}}$. Кривая симметрична относительно точки перегиба с координатами     $t = \frac{ln(b)}{a}, f(t) = \frac{k}{2}$
    keywords: [ Трендовые модели, С пределом роста и точкой перегиба или кривые насыщения, Содержательная интерпретация параметров.]
num58:
    text: |-
        ### 58) Выбор кривой роста.

        Для выбора кривой роста используется метод характеристик прироста, основанный на использовании отдельных характерных свойств. В частности, выражение ряда $Y_t$ с помощью скользящей средней и определение средних приростов и производных величин.

        $\Delta y_t = \frac{y_{t+1} - y_{t-1}}{2}$ - первый средний прирост 

        - постоянна = ПОЛИНОМ ПЕРВОГО ПОРЯДКА
        - линейна = ПОЛИНОМ ВТОРОГО ПОРЯДКА

        $\Delta^2 y_t = \frac{\Delta y_{t+1} - \Delta y_{t-1}}{2}$ - второй средний рост 

        - линейна = ПОЛИНОМ ТРЕТЬЕГО ПОРЯДКА

        $\frac{\Delta y_t}{y_t}$  ,  $ln(\Delta y_t)$,   $ln(\frac{\Delta y_t}{y})$,   $ln(\frac{\Delta y_t}{y_t^2})$  - производные величины = 

        - $\frac{\Delta y_t}{y_t}$  - постоянна = ЭКСПОНЕНТА
        - $ln(\Delta y_t)$ - линейна = МОДИФИЦИРОВАННАЯ ЭКСПОНЕНТА
        - $ln(\frac{\Delta y_t}{y})$ - линейна = КРИВАЯ ГОМПЕРТЦА
        - $ln(\frac{\Delta y_t}{y_t^2})$  - линейна = ЛОГИСТИЧЕСКАЯ КРИВАЯ

        Решение принимается исходя из значений критерия, в качестве которого принимают сумму квадратов отклонений фактических значений уровней от расчетных    
    
    keywords: []
num59:
    text: |-
        ### 59) Прогнозирование с помощью кривой роста.

        - Точечный прогноз:
        Это значение экономического показателя в будущем, определенное путем подстановки значения времени в уравнение выбранной кривой роста. Совпадение фактических данных в будущем и точечного прогнозного значения маловероятно. Точечный прогноз дополняется двухсторонними границами, т.е. таким интервалом, в котором с большей степенью вероятности ожидается фактическое значение прогнозирующего показателя $t = n + k$ .
        Например, для линейной модели прогноз выглядит: 
        $\hat{y}_{прогноз(n+k)}= a_0 + a_1(n + k)$
        
        - Интервальный прогноз:

        Для построения интервального прогноза рассчитывается доверительный интервал. Ширина доверительного интервала для линейной трендовой модели:
        $U(k) = S_{\hat{y}} * t_{\alpha}$  $* \sqrt{1 + \frac{1}{n} + \frac{(n + k - t^*)^2}{\sum^n_{t = 1}(t - t^*)^2}}$,  где  $S_{\hat{y}} = \sqrt{\frac{\sum^n_{t = 1}(e_t)^2}{n - m - 1}}$. Далее считают:

        - Верхняя граница $у_{прогноз} + U(k)$
        - Нижняя граница $у_{прогноз} - U(k)$
        - Если изначально нелинейную модель линеризовали, то доверительный интервал определяют так: U(k) = $S_{\hat{y}} * t_{\alpha} \sqrt{ 1 + \vec{x}^T_0 (X^TX)^{-1} \vec{x}_0}$    
    keywords: [Прогнозирование с помощью кривой роста]
num60:
    text: |-
        ### 60) Прогнозирование временного ряда на основе трендовой модели.

        Такой прогноз называется интервальным, определяется доверительным интервалом:

        $\hat{y}_{факт}(t) = f_t + U(k),$       где $\hat{y}_{факт}(t)$ - фактические значения в будущем, $U(k)$ - доверительный интервал. 

        Величина доверительного интервала зависит от стандартной ошибки аппроксимации временного ряда с помощью кривой роста, от времени упреждения прогноза, от длины временного ряда и от уровня значимости прогноза.

        Стандартная ошибка аппроксимации:   $S_{\hat{Y}} = \sqrt{\frac{\sum_1^n(y_t -\hat{y_t})}{n-m}}$, m - кол параметров тренд мод

        Для линейного тренда доверительный интервал: $U(k) = S_{\hat{y}} * t_{\alpha} * \sqrt{1 + \frac{1}{n} + \frac{3*(n + 2k -1)^2}{n(n^2 - 1)}}$, 

        $k$ - число шагов, на которое делится прогноз, $t_{\alpha}$ - критерий Стьюдента для числа степеней свободы  $n - 2$  уровня значимости $\alpha$. 

        Для полиномов второго и третьего порядка используется выражение, в котором начало отсчета времени перенесено на середину временного ряда наблюдений:

         $U(k) = S_{\hat{y}} * t_{\alpha} * \sqrt{1 + \frac{1}{n} + \frac{t_k^2}{\sum_{t=1}^n t^2} + \frac{\sum_{t=1}^n (t^4 - 2t_k^2) * \sum_{t = 1}^n (t^2 + nt_k^4)}{n * \sum_{t = 1}^n (t^4 - (\sum_{t = 1}^n t^2))^2}}$,     $-\frac{n-1}{2} < t < \frac{n - 1}{2}$

        Длина периода не должна превышать одной трети ряда наблюдений

        Адаптивные модели прогнозирования — это модели, способные приспосабливать свою структуру и параметры **к изменению свойств моделируемого процесса**. Как и в трендовых моделях, основным фактором в адаптивных моделях является время, но наблюдениям (уровням ряда) придаются различные веса в зависимости **от силы их влияния на текущий уровень ряда.** Это позволяет учитывать изменения в тенденции ряда, а также колебания.
        Все адаптивные модели основаны на двух схемах: **скользящего среднего
        и авторегрессии**. В моделях скользящего среднего текущий уровень является средневзвешенной суммой всех предыдущих уровней, причем весовые коэффициенты убывают по мере удаления от текущего уровня. Такие модели хорошо отражают изменение тенденции, но **не позволяют отражать колебания.** В авторегрессионных моделях для расчета текущего уровня используются не все, а только несколько последних значений ряда, при этом значения весовых коэффицентов определяются не их близостью к моделируемому уровню, а **теснотой связи между уровнями.**
        Наиболее часто для краткосрочного прогнозирования изменяющихся процессов используется адаптивная модель Брауна. Она позволяет о**тображать развитие линейной или параболической тенденции, а также рядов без тенденции.**
        Соответственно различают модели нулевого (наивная), первого или второго порядков вида:

        $y_{t+k} = A_0$

        $y_{t+ k} = A_0 + A_1k$

        $y_{t + k} = A_0 + A_1k + A_2k^2$

        где t — текущее время; к — время упреждения.
        Порядок модели определяется априорно из предварительного анализа вре-
        менного ряда и законов развития прогнозируемого процесса.
        Модель первого порядка строится следующим образом:

        По нескольким первым точкам методом наименьших квадратов найдем
        значения параметров $А_0, А_1$ линейной модел (или зададим их):
        $\hat{y} _{прогноз}(t) = A_0 + A_1t$
        Используя найденные параметры, найдем прогнозное значение на следующем шаге:
        $\hat{y}_{прогноз} (t + k) = A_0(t) + A_1(t)k, k = 1.$
        Найдем ошибку прогнозирования:
        $e (t + k) = y (t + k) - \hat{y}_{прогноз} (t + k)$ 
        В соответствии с ошибкой изменим значения параметров модели:
        $A_0(t + 1) = A_0(t) + A_1 (t) + (1 - \beta)^2 e(t)$
        $A_1 (t + 1) = A_1 (t) + (1 - \beta )^2 e(t)$
        где В - коэффициент дисконтирования данных, 0 < B < 1.
        Eсли t < N (т. е. время обучения модели еще не заверши-лось), при t ≥ N будем использовать полученное значение как прогнозное, не изменяя параметров модели.
        Дополним точечный прогноз интервальным:
         $U(k) = S_{\hat{y}} * t_{\alpha} * \sqrt{1 + \frac{1}{n} + \frac{3*(n + 2k -1)^2}{n(n^2 - 1)}}$
        где $t_a$ — значение критерия Стьюдента; $Sy$ — среднеквадратичное отклонение прогнозируемого показателя; п — число наблюдений ряда.    
    keywords: [Прогнозирование временного ряда на основе трендовой модели]